#!/usr/bin/env python
import contextlib as __stickytape_contextlib


@__stickytape_contextlib.contextmanager
def __stickytape_temporary_dir():
	import tempfile
	import shutil
	dir_path = tempfile.mkdtemp()
	try:
		yield dir_path
	finally:
		shutil.rmtree(dir_path)


with __stickytape_temporary_dir() as __stickytape_working_dir:
	def __stickytape_write_module(path, contents):
		import os, os.path

		def make_package(path):
			parts = path.split("/")
			partial_path = __stickytape_working_dir
			for part in parts:
				partial_path = os.path.join(partial_path, part)
				if not os.path.exists(partial_path):
					os.mkdir(partial_path)
					with open(os.path.join(partial_path, "__init__.py"), "wb") as f:
						f.write(b"\n")

		make_package(os.path.dirname(path))

		full_path = os.path.join(__stickytape_working_dir, path)
		with open(full_path, "wb") as module_file:
			module_file.write(contents)


	import sys as __stickytape_sys

	__stickytape_sys.path.insert(0, __stickytape_working_dir)

	__stickytape_write_module('gbvision/__init__.py',
							  b'# constants\r\nfrom .constants import *\r\n\r\n# exceptions\r\nfrom .exceptions import *\r\n\r\n# gui\r\nfrom .gui import *\r\n\r\n# models\r\nfrom .models import *\r\n\r\n# tools\r\nfrom .tools import *\r\n\r\n# utils\r\nfrom .utils import *\r\n\r\n\r\n# configure opencv\r\ndef cv_config():\r\n    """\r\n    configure some opencv stuff so that it doesn\'t cause problems\r\n    called automatically when importing gbvision, and does not need to be called by the user\r\n    """\r\n    import cv2\r\n    if cv2.getVersionString()[0] == \'2\':\r\n        for i in filter(lambda attr: attr.startswith("CV_CAP_PROP"), dir(cv2.cv)):\r\n            object.__setattr__(cv2, i[3:], cv2.cv.__getattribute__(i))\r\n            cv2.__dict__[i[3:]] = cv2.cv.__dict__[i]\r\n\r\n\r\ncv_config()\r\ndel cv_config\r\n')
	__stickytape_write_module('gbvision/constants/__init__.py',
							  b'from .math import EPSILON, SQRT_PI\r\nfrom .types import Frame, Coordinates, Location, RotatedRect, Shape, Number, Color, Circle, Contour, FilterFunction, \\\r\n    Rect, FixedPolygon, Ellipse, Polygon, ROI, Point, Line\r\nfrom .images import COLOR_TYPE\r\nfrom .net import LOCAL_SERVER_IP\r\nfrom .system import CONTOURS_INDEX\r\nfrom .video import VIDEO_FILE_TYPE\r\n')
	__stickytape_write_module('gbvision/constants/math.py',
							  b'import numpy as np\r\n\r\nSQRT_PI = np.sqrt(np.pi)\r\n\r\nEPSILON = 1e-100\r\n')
	__stickytape_write_module('gbvision/constants/types.py',
							  b"from typing import Tuple, List, Union, Callable, TypeVar\r\nfrom numpy import ndarray\r\n\r\nNumber = Union[int, float]\r\nPoint = Tuple[Number, Number]  # (x, y)\r\nContour = ndarray\r\nCircle = Tuple[Tuple[Number, Number], Number]  # ((center_x, center_y), radius)\r\nRect = Tuple[Number, Number, Number, Number]  # (x, y, width, height)\r\nPolygon = Union[List[Point], Contour]\r\nFixedPolygon = List[Point]\r\nRotatedRect = Tuple[Point, Point, float]  # ((center_x, center_y), (width, height), angle in degrees)\r\nEllipse = RotatedRect\r\nFrame = Union[ndarray, None]\r\nColor = Tuple[int, int, int]\r\nFilterFunction = Callable[[Frame], Frame]\r\nCoordinates = Tuple[int, int]\r\nLine = Tuple[Coordinates, Coordinates]\r\nLocation = Union[Tuple[Number, Number, Number], ndarray]\r\nROI = Tuple[int, int, int, int]  # (x, y, width, height)\r\nShape = TypeVar('Shape')\r\n")
	__stickytape_write_module('gbvision/constants/images.py',
							  b"import cv2\r\n\r\nCOLOR_TYPE = {\r\n    name[10:]: getattr(cv2, name) for name in dir(cv2) if name.startswith('COLOR_BGR2')\r\n}\r\n")
	__stickytape_write_module('gbvision/constants/net.py', b"LOCAL_SERVER_IP = '0.0.0.0'\r\n")
	__stickytape_write_module('gbvision/constants/system.py',
							  b"import cv2\r\n\r\nCONTOURS_INDEX = 1 if cv2.getVersionString()[0] == '3' else 0\r\n")
	__stickytape_write_module('gbvision/constants/video.py',
							  b"VIDEO_FILE_TYPE = {\r\n    '.AVI': 'XVID',\r\n    '.MP4': 'MP4V',\r\n    '.MJPEG': 'MJPG',\r\n    '.MJPG': 'MJPG'\r\n}\r\n")
	__stickytape_write_module('gbvision/exceptions/__init__.py',
							  b'from .could_not_read_frame_exception import CouldNotReadFrameException\r\nfrom .device_not_found_exception import DeviceNotFoundException\r\nfrom .stream_closed import StreamClosed\r\nfrom .tcp_stream_closed import TCPStreamClosed\r\nfrom .vision_exception import VisionException\r\nfrom .vision_warning import VisionWarning\r\n')
	__stickytape_write_module('gbvision/exceptions/could_not_read_frame_exception.py',
							  b'from .vision_exception import VisionException\r\n\r\n\r\nclass CouldNotReadFrameException(VisionException):\r\n    """\r\n    this is raised when the camera could not be read from\r\n    """\r\n    pass\r\n')
	__stickytape_write_module('gbvision/exceptions/vision_exception.py',
							  b'class VisionException(Exception):\r\n    """\r\n    generic vision exception\r\n    """\r\n    pass\r\n')
	__stickytape_write_module('gbvision/exceptions/device_not_found_exception.py',
							  b'from .vision_exception import VisionException\r\n\r\n\r\nclass DeviceNotFoundException(VisionException):\r\n    """\r\n    this is raised when the program was not able to connect to the camera\r\n    """\r\n    pass\r\n')
	__stickytape_write_module('gbvision/exceptions/stream_closed.py',
							  b'class StreamClosed(IOError):\r\n    """\r\n    indicates that a stream was closed\r\n    """\r\n')
	__stickytape_write_module('gbvision/exceptions/tcp_stream_closed.py',
							  b'from .stream_closed import StreamClosed\r\n\r\n\r\nclass TCPStreamClosed(StreamClosed):\r\n    """\r\n    indicates that a stream was closed\r\n    """\r\n')
	__stickytape_write_module('gbvision/exceptions/vision_warning.py',
							  b'class VisionWarning(Warning):\r\n    """\r\n    generic vision warning\r\n    """\r\n    pass\r\n')
	__stickytape_write_module('gbvision/gui/__init__.py',
							  b'from .drawing_functions import draw_circles, draw_contours, draw_ellipses, draw_rects, draw_rotated_rects, draw_text, \\\r\n    draw_lines\r\nfrom .drawing_tools import DrawContours, DrawCircles, DrawEllipses, DrawRects, DrawRotatedRects')
	__stickytape_write_module('gbvision/gui/drawing_functions.py',
							  b'from typing import List\r\n\r\nimport cv2\r\nimport numpy as np\r\n\r\nfrom gbvision.constants.types import Frame, Contour, Color, Circle, Rect, RotatedRect, Ellipse, Coordinates, Number, \\\r\n    Line\r\n\r\n\r\ndef draw_contours(frame: Frame, cnts: List[Contour], color: Color, *args, **kwargs) -> Frame:\r\n    """\r\n    draws all contours on a copy of the frame and returns the copy\r\n\r\n    :param frame: the frame to draw on\r\n    :param cnts: the contours to draw\r\n    :param color: the color to draw in\r\n    :param args: all extra args to opencv\'s  drawContours (for example thickness)\r\n    :param kwargs: all extra keyword args to opencv\'s  drawContours (for example thickness)\r\n    :return: a copy of the frame, after drawing\r\n    """\r\n    frame = frame.copy()\r\n    cv2.drawContours(frame, cnts, -1, color, *args, **kwargs)\r\n    return frame\r\n\r\n\r\ndef draw_circles(frame: Frame, circs: List[Circle], color: Color, *args, **kwargs) -> Frame:\r\n    """\r\n    draws all circles on a copy of the frame and returns the copy\r\n\r\n    :param frame: the frame to draw on\r\n    :param circs: the circles to draw\r\n    :param color: the color to draw in\r\n    :param args: all extra args to opencv\'s circle (for example thickness)\r\n    :param kwargs: all extra keyword args to opencv\'s circle (for example thickness)\r\n    :return: a copy of the frame, after drawing\r\n    """\r\n    frame = frame.copy()\r\n    for c in circs:\r\n        cv2.circle(frame, (int(c[0][0]), int(c[0][1])), int(c[1]), color, *args, **kwargs)\r\n    return frame\r\n\r\n\r\ndef draw_rects(frame: Frame, rects: List[Rect], color: Color, *args, **kwargs) -> Frame:\r\n    """\r\n    draws all rects on a copy of the frame and returns the copy\r\n\r\n    :param frame: the frame to draw on\r\n    :param rects: the rects to draw\r\n    :param color: the color to draw in\r\n    :param args: all extra args to opencv\'s rectangle (for example thickness)\r\n    :param kwargs: all extra keyword args to opencv\'s rectangle (for example thickness)\r\n    :return: a copy of the frame, after drawing\r\n    """\r\n    frame = frame.copy()\r\n    for r in rects:\r\n        cv2.rectangle(frame, (int(r[0]), int(r[1])), (int(r[0] + r[2]), int(r[1] + r[3])), color, *args, **kwargs)\r\n    return frame\r\n\r\n\r\ndef draw_rotated_rects(frame: Frame, rotated_rects: List[RotatedRect], color: Color, *args, **kwargs) -> Frame:\r\n    """\r\n    draws all rotated rects on a copy of the frame and returns the copy\r\n\r\n    :param frame: the frame to draw on\r\n    :param rotated_rects: the rotated rects to draw\r\n    :param color: the color to draw in\r\n    :param args: all extra args to opencv\'s drawContours (for example thickness)\r\n    :param kwargs: all extra keyword args to opencv\'s drawContours (for example thickness)\r\n    :return: a copy of the frame, after drawing\r\n    """\r\n    frame = frame.copy()\r\n    for r in rotated_rects:\r\n        box = cv2.boxPoints(r)\r\n        box = np.int0(box)\r\n        cv2.drawContours(frame, [box], 0, color, *args, **kwargs)\r\n    return frame\r\n\r\n\r\ndef draw_ellipses(frame: Frame, ellipses: List[Ellipse], color: Color, *args, **kwargs) -> Frame:\r\n    """\r\n    draws all contours on a copy of the frame and returns the copy\r\n    \r\n    :param frame: the frame to draw on\r\n    :param ellipses: the ellipses to draw\r\n    :param color: the color to draw in\r\n    :param args: all extra args to opencv\'s ellipse (for example thickness)\r\n    :param kwargs: all extra keyword args to opencv\'s ellipse (for example thickness)\r\n    :return: a copy of the frame, after drawing\r\n    """\r\n    frame = frame.copy()\r\n    for e in ellipses:\r\n        cv2.ellipse(frame, e, color, *args, **kwargs)\r\n    return frame\r\n\r\n\r\ndef draw_lines(frame: Frame, lines: List[Line], color: Color, *args, **kwargs) -> Frame:\r\n    """\r\n    draws all Lines on a copy of the frame and returns the copy\r\n\r\n    :param frame: the frame to draw on\r\n    :param lines: the list of lines to draw\r\n    :param color: the color to draw in\r\n    :param args: all extra args to opencv\'s lines (for example thickness)\r\n    :param kwargs: all extra keyword args to opencv\'s lines (for example thickness)\r\n    :return: a copy of the frame, after drawing\r\n    """\r\n\r\n    frame = frame.copy()\r\n    for line in lines:\r\n        cv2.line(frame, line[0], line[1], color, *args, **kwargs)\r\n    return frame\r\n\r\n\r\ndef draw_text(frame: Frame, text: str, coords: Coordinates, font_scale: Number, color: Color,\r\n              font=cv2.FONT_HERSHEY_SIMPLEX, *args, **kwargs) -> Frame:\r\n    """\r\n    draws the text on a copy of the frame and returns the copy\r\n\r\n    :param frame: the frame to draw on\r\n    :param text: the text to draw\r\n    :param coords: the coordinates of the bottom-left corner of the text\r\n    :param font_scale: the size of the drawn text (multiplied by the default size of the font)\r\n    :param color: the color to draw the text in\r\n    :param font: the font, an opencv font constant, default is cv2.FONT_HERSHEY_SIMPLEX\r\n    :param args: additional arguments to cv2.putText\r\n    :param kwargs: additional keyword arguments to cv2.putText (such as thickness)\r\n    :return: a copy of the frame with the text drawn on it\r\n    """\r\n    frame = frame.copy()\r\n    cv2.putText(frame, text, coords, font, font_scale, color, *args, **kwargs)\r\n    return frame\r\n')
	__stickytape_write_module('gbvision/gui/drawing_tools.py',
							  b'from gbvision.constants.types import Color, FilterFunction\r\n\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\nfrom gbvision.models.contours import find_contours, contours_to_circles, contours_to_rects, contours_to_rotated_rects, \\\r\n    contours_to_ellipses\r\nfrom gbvision.utils.pipeline import PipeLine\r\nfrom .drawing_functions import draw_contours, draw_circles, draw_rects, draw_rotated_rects, draw_ellipses\r\n\r\n\r\nclass _DrawObject(PipeLine):\r\n    def __init__(self, finding_func, color, drawing_func, *args, **kwargs):\r\n        def _draw(frame):\r\n            return drawing_func(frame, finding_func(frame), color, *args, **kwargs)\r\n\r\n        PipeLine.__init__(self, _draw)\r\n\r\n\r\nclass DrawContours(_DrawObject):\r\n    """\r\n    a pipeline that draws all contours according to the given parameters, and returns a copy of the frame after drawing\r\n    """\r\n\r\n    def __init__(self, threshold_func: FilterFunction, color: Color, contours_process=EMPTY_PIPELINE, *args,\r\n                 **kwargs):\r\n        contour_finding = EMPTY_PIPELINE + threshold_func + find_contours + contours_process\r\n        _DrawObject.__init__(self, contour_finding, color, draw_contours, *args, **kwargs)\r\n\r\n\r\nclass DrawCircles(_DrawObject):\r\n    """\r\n    a pipeline that draws all circles according to the given parameters, and returns a copy of the frame after drawing\r\n    """\r\n\r\n    def __init__(self, threshold_func: FilterFunction, color: Color, contours_process=EMPTY_PIPELINE,\r\n                 circle_process=EMPTY_PIPELINE, *args, **kwargs):\r\n        circle_finding = EMPTY_PIPELINE + threshold_func + find_contours + contours_process + contours_to_circles + \\\r\n                         circle_process\r\n\r\n        _DrawObject.__init__(self, circle_finding, color, draw_circles, *args, **kwargs)\r\n\r\n\r\nclass DrawRects(_DrawObject):\r\n    """\r\n    a pipeline that draws all rects according to the given parameters, and returns a copy of the frame after drawing\r\n    """\r\n\r\n    def __init__(self, threshold_func: FilterFunction, color: Color, contours_process=EMPTY_PIPELINE,\r\n                 rects_process=EMPTY_PIPELINE, *args, **kwargs):\r\n        rect_finding = EMPTY_PIPELINE + threshold_func + find_contours + contours_process + contours_to_rects + \\\r\n                       rects_process\r\n\r\n        _DrawObject.__init__(self, rect_finding, color, draw_rects, *args, **kwargs)\r\n\r\n\r\nclass DrawRotatedRects(_DrawObject):\r\n    """\r\n    a pipeline that draws all rotated rects according to the given parameters, and returns a copy of the frame after drawing\r\n    """\r\n\r\n    def __init__(self, threshold_func: FilterFunction, color: Color, contours_process=EMPTY_PIPELINE,\r\n                 rotated_rects_process=EMPTY_PIPELINE, *args, **kwargs):\r\n        rotated_rect_finding = EMPTY_PIPELINE + threshold_func + find_contours + contours_process + contours_to_rotated_rects + \\\r\n                               rotated_rects_process\r\n\r\n        _DrawObject.__init__(self, rotated_rect_finding, color, draw_rotated_rects, *args, **kwargs)\r\n\r\n\r\nclass DrawEllipses(_DrawObject):\r\n    """\r\n    a pipeline that draws all ellipses according to the given parameters, and returns a copy of the frame after drawing\r\n    """\r\n\r\n    def __init__(self, threshold_func: FilterFunction, color: Color, contours_process=EMPTY_PIPELINE,\r\n                 ellipses_process=EMPTY_PIPELINE, *args, **kwargs):\r\n        ellipses_finding = EMPTY_PIPELINE + threshold_func + find_contours + contours_process + contours_to_ellipses + \\\r\n                           ellipses_process\r\n\r\n        _DrawObject.__init__(self, ellipses_finding, color, draw_ellipses, *args, **kwargs)\r\n')
	__stickytape_write_module('gbvision/models/__init__.py',
							  b'from .basic_ops import gray, sharpen, blue, blur, corners, red, edges, green, normalize, distance_transform, \\\r\n    normalized_distance_transform\r\nfrom .cameras import LIFECAM_3000, UNKNOWN_CAMERA\r\nfrom .contours import contours_to_rotated_rects, contours_to_rotated_rects_sorted, fix_contours_shape, \\\r\n    sort_rotated_rects, contour_center, contours_centers, contours_to_circles, contours_to_circles_sorted, \\\r\n    contours_to_ellipses, contours_to_ellipses_sorted, contours_to_polygons, contours_to_rects, \\\r\n    contours_to_rects_sorted, convex_hull, convex_hull_multiple, sort_circles, find_contours, polygon_center, \\\r\n    polygons_centers, sort_contours, sort_rects, sort_ellipses, sort_polygons, FilterContours\r\nfrom .shapes import convex_shape_collision, filter_inner_convex_shapes, filter_inner_rotated_rects, \\\r\n    rotated_rect_collision, circle_collision, filter_inner_circles, filter_inner_rects, rect_collision\r\nfrom .system import EMPTY_PIPELINE\r\n')
	__stickytape_write_module('gbvision/models/basic_ops.py',
							  b'import cv2\r\nimport numpy as np\r\n\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\n@PipeLine\r\ndef corners(frame):\r\n    """\r\n    corner finding by a laplacian convolution of the frame by the matrix:\r\n        [-1 1]\r\n        [1 -1]\r\n\r\n    :param frame: the frame to convolve\r\n    :return: the convolved frame\r\n    """\r\n    return cv2.filter2D(frame, -1, np.array([[-1, 1], [1, -1]]))\r\n\r\n\r\n@PipeLine\r\ndef edges(frame):\r\n    """\r\n    edges finding by a laplacian convolution of the frame by the matrix:\r\n        [-1 -1 -1]\r\n        [-1 8 -1]\r\n        [-1 -1 -1]\r\n    :param frame: the frame to convolve\r\n    :return: the convolved frame\r\n    """\r\n    return cv2.Canny(frame, 100, 200)\r\n\r\n\r\n@PipeLine\r\ndef sharpen(frame):\r\n    """\r\n    sharpens the frame by a laplacian convolution of the frame by the matrix:\r\n        [-1 -1 -1]\r\n        [-1 9 -1]\r\n        [-1 -1 -1]\r\n\r\n    :param frame: the frame to convolve\r\n    :return: the convolved frame\r\n    """\r\n    return cv2.filter2D(frame, -1, np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]))\r\n\r\n\r\n@PipeLine\r\ndef blur(frame):\r\n    """\r\n    blurs the frame by a laplacian convolution of the frame by the matrix:\r\n        [1/9 1/9 1/9]\r\n        [1/9 1/9 1/9]\r\n        [1/9 1/9 1/9]\r\n\r\n    :param frame: the frame to convolve\r\n    :return: the convolved frame\r\n    """\r\n    return cv2.filter2D(frame, -1, np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9)\r\n\r\n\r\n@PipeLine\r\ndef blue(frame):\r\n    """\r\n    gets the blue channel of the frame\r\n\r\n    :param frame: the frame\r\n    :return: the blue channel only (as a grayscale frame)\r\n    """\r\n    return frame[:, :, 0]\r\n\r\n\r\n@PipeLine\r\ndef green(frame):\r\n    """\r\n    gets the green channel of the frame\r\n\r\n    :param frame: the frame\r\n    :return: the green channel only (as a grayscale frame)\r\n    """\r\n    return frame[:, :, 1]\r\n\r\n\r\n@PipeLine\r\ndef red(frame):\r\n    """\r\n    gets the red channel of the frame\r\n\r\n    :param frame: the frame\r\n    :return: the red channel only (as a grayscale frame)\r\n    """\r\n    return frame[:, :, 2]\r\n\r\n\r\n@PipeLine\r\ndef gray(frame):\r\n    """\r\n    turns the frame to grayscale\r\n\r\n    :param frame: the frame\r\n    :return: the frame in grayscale form\r\n    """\r\n    return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n\r\n\r\n@PipeLine\r\ndef normalize(frame):\r\n    """\r\n    normalizes the frame to a pixel range of 0-1\r\n    equivalent to (frame - min(frame)) / max(abs(frame - min(frame)))\r\n\r\n    :param frame: the frame\r\n    :return: the normalized frame (data type float32)\r\n    """\r\n    return cv2.normalize(frame, None, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\r\n\r\n\r\n@PipeLine\r\ndef distance_transform(frame):\r\n    """\r\n    performs the distance transform algorithm on a binary frame\r\n\r\n    :param frame: the frame (binary, usually after threshold)\r\n    :return: the distance transform of the frame using euclidean distance method\r\n    """\r\n    return cv2.distanceTransform(frame, cv2.DIST_L2, 3)\r\n\r\n\r\nnormalized_distance_transform = distance_transform + normalize\r\n')
	__stickytape_write_module('gbvision/utils/__init__.py',
							  b'from .async_readable import AsyncReadable\r\nfrom .game_object import GameObject\r\nfrom .pipeline import PipeLine\r\nfrom .readable import Readable\r\nfrom .tracker import Tracker\r\nfrom .cameras import *\r\nfrom .continuity import *\r\nfrom .finders import *\r\nfrom .net import *\r\nfrom .thresholds import *\r\nfrom .shapes import *\r\nfrom .recorders import *\r\nfrom .denoising import *\r\n')
	__stickytape_write_module('gbvision/utils/async_readable.py',
							  b'import abc\r\nimport time\r\nfrom threading import Thread\r\nfrom typing import Tuple\r\n\r\nfrom gbvision.constants.types import Frame\r\nfrom gbvision.utils.readable import Readable\r\n\r\n\r\nclass AsyncReadable(Readable, abc.ABC):\r\n    """\r\n    an async readable class that constantly reads on another thread\r\n    """\r\n\r\n    def __init__(self):\r\n        self.__ok, self.__frame = False, None\r\n        self.__thread = Thread(target=self.__async_read_wrapper)\r\n        self.__thread.start()\r\n\r\n    def read(self):\r\n        return self.__ok, self.__frame\r\n\r\n    def has_started_reading(self) -> bool:\r\n        """\r\n        checks if the async thread has started reading\r\n\r\n        :return: True if the async thread started, False otherwise\r\n        """\r\n        return self.__ok\r\n\r\n    def wait_start_reading(self, wait_time=0.01):\r\n        """\r\n        waits until the async thread starts reading\r\n\r\n        :param wait_time: amounts of seconds to wait in every check interval, default is 0.01\r\n        :return:\r\n        """\r\n        while not self.has_started_reading():\r\n            time.sleep(wait_time)\r\n\r\n    @abc.abstractmethod\r\n    def _read(self) -> Tuple[bool, Frame]:\r\n        """\r\n        reads from the camera synchronously (similar to Readable.read), unsafe, not to use by the programmer\r\n        this method will usually simply call super(self, ReadableClass).read()\r\n\r\n        :return: tuple of bool (indicates if read was successful) and the frame (if successful, else None)\r\n        """\r\n\r\n    def __async_read_wrapper(self):\r\n        while True:\r\n            self.__ok, self.__frame = self._read()\r\n')
	__stickytape_write_module('gbvision/utils/readable.py',
							  b'import abc\r\nfrom typing import Tuple\r\n\r\nfrom gbvision.constants.types import Frame\r\n\r\n\r\nclass Readable(abc.ABC):\r\n    """\r\n    an interface representing an object you can read frames from, such as cameras and streams\r\n    """\r\n\r\n    @abc.abstractmethod\r\n    def read(self) -> Tuple[bool, Frame]:\r\n        """\r\n        reads from the readable and returns the result\r\n\r\n        :return: False, None if the operation was unsuccessful, else True, frame_result\r\n        """\r\n')
	__stickytape_write_module('gbvision/utils/game_object.py',
							  b'import cv2\r\nimport numpy as np\r\n\r\nfrom gbvision.constants.math import EPSILON\r\nimport gbvision.utils.cameras as cameras\r\nfrom gbvision.models.contours import contour_center\r\nfrom gbvision.constants.types import Point, Contour, Number, Location\r\n\r\n\r\nclass GameObject:\r\n    """\r\n    constructor of the image object\r\n    which is an object on field\r\n\r\n    :param area: the square root of the surface area of the object in real life\r\n\r\n    """\r\n\r\n    def __init__(self, area: Number):\r\n        self.area = area\r\n\r\n    def distance_by_contours(self, camera: cameras.Camera, cnt: Contour) -> float:\r\n        """\r\n        Note: this measures the distance between the camera and the object, to use another measuring point\r\n        calculate the norm of the location\r\n        \r\n        :param camera: the camera, can be either Camera or CameraList\r\n        :param cnt: the contours of this object in the frame\r\n        :return: the norm of the vector between the camera and the object (in meters)\r\n        """\r\n        return self.distance_by_params(camera, np.sqrt(cv2.contourArea(cnt)))\r\n\r\n    def distance_by_params(self, camera: cameras.Camera, area: Number) -> float:\r\n        """\r\n        Note: this measures the distance between the camera and the object, to use another measuring point\r\n        calculate the norm of the location\r\n\r\n        :param camera: the camera, can be either Camera or CameraList\r\n        :param area: a float representing the square root of the area of the object\r\n            (in pixels)\r\n        :return: the norm of the vector between the camera and the object (in meters)\r\n        """\r\n        return camera.get_data().focal_length * self.area / (area + EPSILON)\r\n\r\n    def location_by_contours(self, camera: cameras.Camera, cnt: Contour) -> Location:\r\n        """\r\n        :param camera: the camera, can be either Camera or CameraList\r\n        :param cnt: the contours of this object in the frame\r\n        :return: a 3d vector of the relative [x y z] location between the object and the camera (in meters)\r\n        """\r\n        return self.location_by_params(camera, np.sqrt(cv2.contourArea(cnt)), contour_center(cnt))\r\n\r\n    def location_by_params(self, camera: cameras.Camera, area: Number, center: Point) -> Location:\r\n        """\r\n        :param camera: the camera, can be either Camera or CameraList\r\n        :param area: a float representing the square root of the area of the object (in pixels)\r\n        :param center: the center (x,y) of this object in the frame\r\n        :return: a 3d vector of the relative [x y z] location between the object and the camera/measuring point (in meters)\r\n        """\r\n        frame_center = camera.get_width(), camera.get_height()\r\n        frame_center = np.array(frame_center) / 2\r\n        x, y = np.array(center) - frame_center\r\n        alpha = x * camera.get_data().fov_width / frame_center[0]\r\n        beta = y * camera.get_data().fov_height / frame_center[1]\r\n        rel = np.array([[np.sin(alpha), np.sin(beta),\r\n                         np.sqrt(1 - np.sin(alpha) ** 2 - np.sin(beta) ** 2)]]) * self.distance_by_params(camera, area)\r\n        return camera.get_data().rotation_matrix.dot(rel.T).flatten() + camera.get_data().offset\r\n')
	__stickytape_write_module('gbvision/utils/cameras/__init__.py',
							  b'from .async_camera import AsyncCamera\r\nfrom .async_usb_camera import AsyncUSBCamera\r\nfrom .camera import Camera\r\nfrom .camera_data import CameraData\r\nfrom .camera_list import CameraList\r\nfrom .empty_camera import EmptyCamera\r\nfrom .stream_camera import StreamCamera, SimpleStreamCamera\r\nfrom .usb_camera import USBCamera\r\nfrom .usb_stream_camera import USBStreamCamera\r\n')
	__stickytape_write_module('gbvision/utils/cameras/async_camera.py',
							  b'import abc\r\nfrom .camera import Camera\r\nfrom gbvision.utils.async_readable import AsyncReadable\r\n\r\n\r\nclass AsyncCamera(Camera, AsyncReadable, abc.ABC):\r\n    """\r\n    an abstract class that represents an async camera\r\n    the async camera is similar to a regular camera, but executes the read actions on another thread\r\n    thus not blocking the processing thread\r\n\r\n    you will usually want to inherit from this class and from another camera class in order to use the async functionality\r\n    for example:\r\n\r\n    Example::\r\n        class AsyncUSBCamera(AsyncCamera, USBCamera):\r\n            def _read(self) -> Tuple[bool, Frame]:\r\n                return USBCamera.read(self)\r\n\r\n            def __init__(self, port, data=UNKNOWN_CAMERA):\r\n                USBCamera.__init__(self, port, data)\r\n                AsyncCamera.__init__(self)\r\n    """\r\n\r\n    def __init__(self):\r\n        AsyncReadable.__init__(self)\r\n')
	__stickytape_write_module('gbvision/utils/cameras/camera.py',
							  b'import abc\r\nfrom typing import Union\r\n\r\nimport numpy as np\r\nfrom gbvision.constants.types import Number\r\n\r\nfrom .camera_data import CameraData\r\nfrom gbvision.utils.readable import Readable\r\n\r\n\r\nclass Camera(Readable, abc.ABC):\r\n    """\r\n    an abstract class representing a camera\r\n    """\r\n\r\n    @abc.abstractmethod\r\n    def release(self):\r\n        """\r\n        closes the handle to this camera, if it is not necessary please override this method to a blank method\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def is_opened(self) -> bool:\r\n        """\r\n        checks if the camera can be read from\r\n\r\n        :return: True if the camera can be read from, otherwise False\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def set_exposure(self, exposure: Union[int, float, bool]) -> bool:\r\n        """\r\n        sets the camera\'s exposure\r\n\r\n        :param exposure: the new exposure\r\n        :return: True on success, False on failure\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def set_auto_exposure(self, auto: Union[int, float, bool]) -> bool:\r\n        """\r\n        sets the camera\'s auto exposure\r\n\r\n        :param auto: the new auto exposure\r\n        :return: True on success, False on failure\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def get_data(self) -> CameraData:\r\n        """\r\n        :return: this camera\'s constant descriptor (must be the real descriptor, can\'t be a copy) \\\r\n            when the values of this descriptor are changed, the values of the real camera descriptor must also change\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def get_width(self) -> int:\r\n        """\r\n        :return: the width of a frame read from this camera\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def get_height(self) -> int:\r\n        """\r\n        :return: the height of a frame read from this camera\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def _set_width(self, width: int):\r\n        """\r\n        unsafe set width\r\n        supposed to be overridden and only used by rescale, resize and set_frame size methods\r\n        never to be used by the programmer, only by the api\r\n\r\n        :param width: new width\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def _set_height(self, height: int):\r\n        """\r\n        unsafe set height\r\n        supposed to be overridden and only used by rescale, resize and set_frame size methods\r\n        never to be used by the programmer, only by the api\r\n\r\n        :param height: new height\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def get_fps(self) -> Number:\r\n        """\r\n        gets the fps of this camera\r\n\r\n        :return: the fps of the camera\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def set_fps(self, fps: Number) -> bool:\r\n        """\r\n        sets the fps for this camera\r\n\r\n        :return: True on success, False otherwise\r\n        """\r\n\r\n    def rescale(self, factor: float):\r\n        """\r\n        rescale the size of the frames read from this camera by a factor\r\n\r\n        :param factor: the rescaling factor\r\n        """\r\n        self._set_width(int(self.get_width() * factor))\r\n        self._set_height(int(self.get_height() * factor))\r\n        self.get_data().focal_length *= factor\r\n\r\n    def resize(self, fx: float, fy: float):\r\n        """\r\n        rescale the size of the frames read from this camera by different width and height factors\r\n\r\n        :param fx: the width factor\r\n        :param fy: the height factor\r\n        """\r\n        self._set_width(int(self.get_width() * fx))\r\n        self._set_height(int(self.get_height() * fy))\r\n        self.get_data().focal_length *= np.sqrt(fx * fy)\r\n\r\n    def set_frame_size(self, width: int, height: int):\r\n        """\r\n        reset the width and height of frames read from this camera to given values\r\n        \r\n        :param width: the new width\r\n        :param height: the new height\r\n        """\r\n        old_width, old_height = self.get_width(), self.get_height()\r\n        self._set_height(height)\r\n        self._set_width(width)\r\n        self.get_data().focal_length *= np.sqrt(width * height / (old_width * old_height))\r\n')
	__stickytape_write_module('gbvision/utils/cameras/camera_data.py',
							  b'import numpy as np\r\nfrom copy import deepcopy\r\n\r\nfrom gbvision.constants.types import Number\r\n\r\n\r\nclass CameraData:\r\n    """\r\n    describes constant about a camera in it\'s default state used to approximate distance\r\n    between the camera and an object seen in a frame\r\n\r\n    :param focal_length: the focal length of the camera at it\'s default state, in units of pixels\r\n        can be described as the square root of the amount of pixels an object takes on a frame, multiplied by it\'s\r\n        distance from the camera and divided by the square root of it\'s surface\r\n\r\n        FOCAL_LENGTH = :math:\' sqrt(P) * D / sqrt(S)\'\r\n\r\n        where P is the amount of pixels in the frame representing the object,\r\n        D is the real life distance between the object and the camera\r\n        S is the real life surface area (in 2d projection) of the object\r\n        note that this is a constant, whatever object you choose to use, this formula will yield the same result\r\n    :param fov_width:\r\n        half the viewing angle of the camera (field of view) in radians, can be calculated by placing an object in front\r\n        of the camera, so that the entire object is captured and it\'s center is at the frame\'s center.\r\n        the tangent of the angle can be described as the width of the object in real life, divided by the\r\n        product of the object\'s distance from the camera in real life and the ratio between the width of the frame\r\n        in pixels and the width of the object in the frame, also in pixels\r\n\r\n        math:: tan(FOV) = (Wm) / (D * (Wp/Wf))\r\n\r\n        where Wm is the real life width of the object\r\n        D is the real life distance between the object and the camera\r\n        Wp is the width of the object in the frame (pixels unit)\r\n        Wf is the width of the frame (pixels unit)\r\n        to calculate the FOV just apply the inverse tangent\r\n\r\n        FOV = math:: arctan(tan(FOV))\r\n\r\n    :param fov_height:\r\n        same as fov_width but on the height/y axis\r\n\r\n    :param yaw_angle:\r\n        the clockwise yaw angle (in radians) in which the camera is rotated, the yaw angle is the angle around the y axis,\r\n        it\'s output only affects the x and z axises.\r\n        set this variable when the camera is rotated around the y axis and you want the output of finder functions\r\n        to represent the original space, rather then the rotated one.\r\n    :param pitch_angle:\r\n        the clockwise pitch angle (in radians) in which the camera is rotated, the pitch angle is the angle around the x axis,\r\n        it\'s output only affects the y and z axises.\r\n        set this variable when the camera is rotated around the x axis and you want the output of finder functions\r\n        to represent the original space, rather then the rotated one.\r\n    :param roll_angle:\r\n        the clockwise roll angle (in radians) in which the camera is rotated, the roll angle is the angle around the z axis,\r\n        it\'s output only affects the x and y axises.\r\n        set this variable when the camera is rotated around the z axis and you want the output of finder functions\r\n        to represent the original space, rather then the rotated one.\r\n    :param x_offset:\r\n        the x offset in which the camera is placed\r\n        the distance from the measuring point (usually the center of the robot) to the camera on the x axis (left/right),\r\n        if the camera is to the right this should be positive and if it is left this should be negative\r\n    :param y_offset:\r\n        the y offset in which the camera is placed\r\n        the distance from the measuring point to the camera on the y axis (up/down), if the camera is above the measuring point\r\n        this variable should be positive and if it is below this should be negative\r\n    :param z_offset:\r\n        the z offset in which the camera is placed\r\n        the distance from the measuring point to the camera on the z axis (depth), if the camera is placed outer then the measuring point\r\n        this variable should be positive and if it is inner this should be negative\r\n    :param is_immutable: determines whether the camera data object\'s values are immutable (True) or mutable (False)\r\n    """\r\n\r\n    def __init__(self, focal_length, fov_width, fov_height, pitch_angle=0, yaw_angle=0, roll_angle=0, x_offset=0, y_offset=0, z_offset=0,\r\n                 is_immutable=False, name=None):\r\n        self.focal_length = focal_length\r\n        self.fov_width = fov_width\r\n        self.fov_height = fov_height\r\n        self.rotation_angles = np.array([pitch_angle, yaw_angle, roll_angle])\r\n        self.rotation_matrix = self.__calculate_rotation_matrix()\r\n        self.offset = np.array([x_offset, y_offset, z_offset])\r\n        self.name = name\r\n        self.__is_immutable = is_immutable\r\n\r\n    def __calculate_rotation_matrix(self):\r\n\r\n        pitch_angle, yaw_angle, roll_angle = self.rotation_angles\r\n        sin, cos = np.sin(yaw_angle), np.cos(yaw_angle)\r\n        rotation_matrix = np.array([[cos, 0, sin],\r\n                                    [0, 1, 0],\r\n                                    [-sin, 0, cos]])\r\n        sin, cos = np.sin(pitch_angle), np.cos(pitch_angle)\r\n        rotation_matrix = rotation_matrix.dot(np.array([[1, 0, 0],\r\n                                                        [0, cos, -sin],\r\n                                                        [0, sin, cos]]))\r\n        sin, cos = np.sin(roll_angle), np.cos(roll_angle)\r\n        rotation_matrix = rotation_matrix.dot(np.array([[cos, -sin, 0],\r\n                                                        [sin, cos, 0],\r\n                                                        [0, 0, 1]]))\r\n        return rotation_matrix\r\n\r\n    def __get_data(self) -> \'CameraData\':\r\n        return self.copy() if self.__is_immutable else self\r\n\r\n    def rotate_pitch(self, angle: float) -> \'CameraData\':\r\n        """\r\n        rotates the camera\'s angle around the pitch axis (the x axis)\r\n\r\n        :param angle: the rotation angle\r\n        :return: a camera data instance with the same params as this but with the pitch angle rotated \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.rotation_angles[0] += angle\r\n        sin, cos = np.sin(angle), np.cos(angle)\r\n        data.rotation_matrix = data.rotation_matrix.dot(np.array([[1, 0, 0],\r\n                                                                  [0, cos, -sin],\r\n                                                                  [0, sin, cos]]))\r\n        return data\r\n\r\n    def rotate_yaw(self, angle: float) -> \'CameraData\':\r\n        """\r\n        rotates the camera\'s angle around the yaw axis (the y axis)\r\n\r\n        :param angle: the rotation angle\r\n        :return: a camera data instance with the same params as this but with the yaw angle rotated \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.rotation_angles[1] += angle\r\n        sin, cos = np.sin(angle), np.cos(angle)\r\n        data.rotation_matrix = data.rotation_matrix.dot(np.array([[cos, 0, sin],\r\n                                                                  [0, 1, 0],\r\n                                                                  [-sin, 0, cos]]))\r\n        return data\r\n\r\n    def rotate_roll(self, angle: float) -> \'CameraData\':\r\n        """\r\n        rotates the camera\'s angle around the roll axis (the z axis)\r\n\r\n        :param angle: the rotation angle\r\n        :return: a camera data instance with the same params as this but with the roll angle rotated \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.rotation_angles[2] += angle\r\n        sin, cos = np.sin(angle), np.cos(angle)\r\n        data.rotation_matrix = data.rotation_matrix.dot(np.array([[cos, -sin, 0],\r\n                                                                  [sin, cos, 0],\r\n                                                                  [0, 0, 1]]))\r\n        return data\r\n\r\n    def set_pitch_angle(self, angle: float) -> \'CameraData\':\r\n        """\r\n        sets the camera\'s angle around the pitch axis (the x axis)\r\n\r\n        :param angle: the rotation angle\r\n        :return: a camera data instance with the same params as this but with the pitch angle changed \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.rotation_angles[0] = angle\r\n        data.rotation_matrix = data.__calculate_rotation_matrix()\r\n        return data\r\n\r\n    def set_yaw_angle(self, angle: float) -> \'CameraData\':\r\n        """\r\n        sets the camera\'s angle around the yaw axis (the y axis)\r\n\r\n        :param angle: the rotation angle\r\n        :return: a camera data instance with the same params as this but with the yaw angle changed \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.rotation_angles[1] = angle\r\n        data.rotation_matrix = data.__calculate_rotation_matrix()\r\n        return data\r\n\r\n    def set_roll_angle(self, angle: float) -> \'CameraData\':\r\n        """\r\n        sets the camera\'s angle around the roll axis (the z axis)\r\n\r\n        :param angle: the rotation angle\r\n        :return: a camera data instance with the same params as this but with the roll angle changed \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.rotation_angles[2] = angle\r\n        data.rotation_matrix = data.__calculate_rotation_matrix()\r\n        return data\r\n\r\n    def move_x(self, x: Number) -> \'CameraData\':\r\n        """\r\n        moves this camera data\'s x axis offset\r\n\r\n        :param x: the x offset to move by\r\n        :return: a camera data instance with the same params as this but with the x axis moved \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.offset[0] += x\r\n        return data\r\n\r\n    def move_y(self, y: Number) -> \'CameraData\':\r\n        """\r\n        moves this camera data\'s y axis offset\r\n\r\n        :param y: the y offset to move by\r\n        :return: a camera data instance with the same params as this but with the y axis moved \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.offset[1] += y\r\n        return data\r\n\r\n    def move_z(self, z: Number) -> \'CameraData\':\r\n        """\r\n        moves this camera data\'s z axis offset\r\n\r\n        :param z: the z offset to move by\r\n        :return: a camera data instance with the same params as this but with the z axis moved \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.offset[2] += z\r\n        return data\r\n\r\n    def set_x_offset(self, x: Number) -> \'CameraData\':\r\n        """\r\n        sets this camera data\'s x axis offset\r\n\r\n        :param x: the new x offset\r\n        :return: a camera data instance with the same params as this but with the x axis changed \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.offset[0] = x\r\n        return data\r\n\r\n    def set_y_offset(self, y: Number) -> \'CameraData\':\r\n        """\r\n        sets this camera data\'s y axis offset\r\n\r\n        :param y: the new y offset\r\n        :return: a camera data instance with the same params as this but with the y axis changed \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.offset[1] = y\r\n        return data\r\n\r\n    def set_z_offset(self, z: Number) -> \'CameraData\':\r\n        """\r\n        sets this camera data\'s z axis offset\r\n\r\n        :param z: the new z offset\r\n        :return: a camera data instance with the same params as this but with the z axis changed \\\r\n            if this is immutable it will return a copy of this, otherwise it will modify this instance and return it\r\n        """\r\n        data = self.__get_data()\r\n        data.offset[2] = z\r\n        return data\r\n\r\n    def copy(self) -> \'CameraData\':\r\n        """\r\n        creates a mutable copy of this and returns it\r\n        :return:\r\n        """\r\n        copy = deepcopy(self)\r\n        copy.__is_immutable = False\r\n        return copy\r\n\r\n    def is_immutable(self) -> bool:\r\n        """\r\n        checks if this camera data instance is immutable\r\n\r\n        :return: True if this is immutable, False otherwise\r\n        """\r\n        return self.__is_immutable\r\n\r\n    def as_immutable(self) -> \'CameraData\':\r\n        """\r\n        creates and returns an immutable copy of this camera data\r\n        if this instance is already immutable it will return this instance\r\n\r\n        :return: an instance of CameraData, with the same values as this instance but immutable\r\n        """\r\n        if self.__is_immutable:\r\n            return self\r\n        copy = self.copy()\r\n        copy.__is_immutable = True\r\n        return copy\r\n\r\n    def __str__(self):\r\n        if self.name is not None:\r\n            return f\'{self.name}\'\r\n        return object.__str__(self)\r\n\r\n    def __repr__(self):\r\n        return str(self)\r\n')
	__stickytape_write_module('gbvision/utils/cameras/async_usb_camera.py',
							  b'from typing import Tuple\r\n\r\nfrom gbvision.constants.types import Frame\r\nfrom .usb_camera import USBCamera\r\nfrom .async_camera import AsyncCamera\r\nfrom gbvision.models.cameras import UNKNOWN_CAMERA\r\n\r\n\r\nclass AsyncUSBCamera(AsyncCamera, USBCamera):\r\n    """\r\n    A simple async usb camera\r\n    """\r\n\r\n    def _read(self) -> Tuple[bool, Frame]:\r\n        return USBCamera.read(self)\r\n\r\n    def __init__(self, port, data=UNKNOWN_CAMERA):\r\n        USBCamera.__init__(self, port, data)\r\n        AsyncCamera.__init__(self)\r\n')
	__stickytape_write_module('gbvision/utils/cameras/usb_camera.py',
							  b'from .camera import CameraData, Camera\r\nfrom gbvision.models.cameras import UNKNOWN_CAMERA\r\nimport cv2\r\nimport platform\r\nimport sys\r\nimport subprocess\r\n\r\n\r\nclass USBCamera(cv2.VideoCapture, Camera):\r\n    """\r\n    a basic usb connected camera which inherits from cv2 VideoCapture\r\n\r\n    :param port: the usb port to which the camera is connected\r\n    :param data: the camera data object that describes this camera\r\n    """\r\n\r\n    def __init__(self, port: int, data: CameraData = UNKNOWN_CAMERA):\r\n        """\r\n        initializes the camera\r\n        \r\n        """\r\n        cv2.VideoCapture.__init__(self, port)\r\n        self._data = data.copy()\r\n        self.port = port\r\n\r\n    def is_opened(self) -> bool:\r\n        return self.isOpened()\r\n\r\n    @staticmethod\r\n    def __is_on_linux() -> bool:\r\n        return platform.system() == \'Linux\'\r\n\r\n    def __v4l2_ctl_command(self, cmd, value) -> int:\r\n        try:\r\n            return subprocess.call([\'v4l2-ctl\', \'-d\', f\'/dev/video{self.port}\', \'-c\', f\'{cmd}={value}\'])\r\n        except FileNotFoundError:\r\n            print(\r\n                "[WARN] setting some parameters such as exposure may not on a Linux machine work if you do not have "\r\n                "v4l2 installed, if the command you tried to run does not work please install v4l2 using \'sudo apt "\r\n                "install v4l-utils\'",\r\n                file=sys.stderr)\r\n            return -1\r\n\r\n    def set_exposure(self, exposure) -> bool:\r\n        if self.__is_on_linux():\r\n            if type(exposure) is bool:\r\n                _exposure = int(exposure) + 10\r\n            else:\r\n                _exposure = exposure\r\n            code = self.__v4l2_ctl_command(\'exposure_absolute\', _exposure)\r\n            if code == 0:\r\n                return True\r\n        if type(exposure) is bool:\r\n            return self.set(cv2.CAP_PROP_EXPOSURE, int(exposure))\r\n        return self.set(cv2.CAP_PROP_EXPOSURE, exposure)\r\n\r\n    def set_auto_exposure(self, auto) -> bool:\r\n        if self.__is_on_linux():\r\n            if type(auto) is bool:\r\n                _auto = 3 if auto else 1\r\n            else:\r\n                _auto = auto\r\n            code = self.__v4l2_ctl_command(\'exposure_auto\', _auto)\r\n            if code == 0:\r\n                return True\r\n        if type(auto) is bool:\r\n            return self.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.75 if auto else 0.25)\r\n        return self.set(cv2.CAP_PROP_AUTO_EXPOSURE, auto)\r\n\r\n    def get_data(self):\r\n        return self._data\r\n\r\n    def get_width(self):\r\n        return self.get(cv2.CAP_PROP_FRAME_WIDTH)\r\n\r\n    def get_height(self):\r\n        return self.get(cv2.CAP_PROP_FRAME_HEIGHT)\r\n\r\n    def _set_width(self, width):\r\n        return self.set(cv2.CAP_PROP_FRAME_WIDTH, width)\r\n\r\n    def _set_height(self, height):\r\n        return self.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\r\n\r\n    def get_fps(self):\r\n        return self.get(cv2.CAP_PROP_FPS)\r\n\r\n    def set_fps(self, fps):\r\n        return self.set(cv2.CAP_PROP_FPS, fps)\r\n')
	__stickytape_write_module('gbvision/models/cameras.py',
							  b"from gbvision.utils.cameras.camera_data import CameraData\r\n\r\n# LIFECAM_STUDIO = CameraData(648.5256168410046, 0.340394, 0, is_immutable=True, name='LIFECAM_STUDIO')\r\n\r\nLIFECAM_3000 = CameraData(697.0395744431028, 0.4435563306578366, 0.3337068395920225, is_immutable=True,\r\n                          name='LIFECAM_3000')\r\n\r\nUNKNOWN_CAMERA = CameraData(0, 0, 0, is_immutable=True, name='UNKNOWN_CAMERA')\r\n")
	__stickytape_write_module('gbvision/utils/cameras/camera_list.py',
							  b'from typing import Union, List, Generator, Any, Tuple\r\n\r\nfrom .camera_data import CameraData\r\nfrom .stream_camera import Camera, StreamCamera\r\nfrom gbvision.constants.types import Frame, Number\r\n\r\n\r\nclass CameraList(Camera):\r\n    """\r\n    behaves as both a camera and a list of cameras\r\n    camera list holds in it a list of cameras referenced as the field cameras\r\n    and also a single camera to be the current camera used for every operation on the camera list\r\n    as a single camera\r\n\r\n    :param cameras: list of the cameras which will be part of the camera list\r\n        you can also add and remove cameras later using the\r\n    :param select_cam: optional, an initial camera to be selected, if not set default camera is the first\r\n        one in the list\r\n    """\r\n\r\n    def __init__(self, cameras: List[Camera], select_cam: int = None):\r\n        self.cameras: List[Camera] = cameras.copy()\r\n        if select_cam is None and len(cameras) > 0:\r\n            select_cam = 0\r\n        self.selected_camera: Union[Camera, StreamCamera] = self.cameras[select_cam] if select_cam is not None else None\r\n\r\n    def __getitem__(self, item: int) -> Camera:\r\n        """\r\n        returns the camera at the index\r\n        :param item: the index\r\n        :return: the camera\r\n        """\r\n        return self.cameras[item]\r\n\r\n    def __setitem__(self, item: int, value: Camera):\r\n        """\r\n        sets the camera at the index to the new camera\r\n        :param item: the index\r\n        :param value: the new camera\r\n        """\r\n        self.cameras[item] = value\r\n\r\n    def select_camera(self, index: int):\r\n        """\r\n        sets the selected camera to be the camera at the index\r\n        :param index: the new selected camera\'s index\r\n        """\r\n        self.selected_camera = self.cameras[index]\r\n\r\n    def __delitem__(self, item: int):\r\n        """\r\n        deletes the camera at the index\r\n        :param item:\r\n        """\r\n        if self.selected_camera is self.cameras[item]:\r\n            self.selected_camera = None\r\n        del self.cameras[item]\r\n\r\n    def __iter__(self):\r\n        """\r\n        :return: an iterator that iterates through all the cameras\r\n        """\r\n        return iter(self.cameras)\r\n\r\n    def __len__(self):\r\n        return len(self.cameras)\r\n\r\n    def read(self, foreach=False) -> Union[Tuple[bool, Frame], Generator[Tuple[bool, Frame], Any, None]]:\r\n        if foreach:\r\n            return (cam.read() for cam in self.cameras)\r\n        return self.selected_camera.read()\r\n\r\n    def is_opened(self, foreach=False) -> Union[bool, Generator[bool, Any, None]]:\r\n        if foreach:\r\n            return (cam.is_opened() for cam in self.cameras)\r\n        return self.selected_camera.is_opened()\r\n\r\n    def add_camera(self, cam: Camera):\r\n        """\r\n        adds a new camera to the end of the list\r\n        :param cam: the new camera\r\n        """\r\n        self.cameras.append(cam)\r\n\r\n    def release(self, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                cam.release()\r\n        else:\r\n            self.selected_camera.release()\r\n            self.selected_camera = None\r\n\r\n    def default(self):\r\n        """\r\n        sets the selected camera to the default camera (first camera in the list)\r\n        """\r\n        self.selected_camera = self.cameras[0] if len(self.cameras) > 0 else None\r\n\r\n    def set_exposure(self, exposure, foreach=False) -> Union[bool, List[bool]]:\r\n        if foreach:\r\n            return [cam.set_exposure(exposure) for cam in self.cameras]\r\n        else:\r\n            return self.selected_camera.set_exposure(exposure)\r\n\r\n    def set_auto_exposure(self, auto, foreach=False) -> Union[bool, List[bool]]:\r\n        if foreach:\r\n            return [cam.set_auto_exposure(auto) for cam in self.cameras]\r\n        else:\r\n            return self.selected_camera.set_auto_exposure(auto)\r\n\r\n    def get_data(self, foreach=False) -> Union[CameraData, Generator[CameraData, Any, None]]:\r\n        if foreach:\r\n            return (cam.get_data() for cam in self.cameras)\r\n        return self.selected_camera.get_data()\r\n\r\n    def resize(self, x_factor, y_factor, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                cam.resize(x_factor, y_factor)\r\n        else:\r\n            self.selected_camera.resize(x_factor, y_factor)\r\n\r\n    def rescale(self, factor, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                cam.rescale(factor)\r\n        else:\r\n            self.selected_camera.rescale(factor)\r\n\r\n    def set_frame_size(self, width, height, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                cam.set_frame_size(width, height)\r\n        else:\r\n            self.selected_camera.set_frame_size(width, height)\r\n\r\n    def toggle_stream(self, should_stream, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                if isinstance(cam, StreamCamera):\r\n                    cam.toggle_stream(should_stream)\r\n        else:\r\n            self.selected_camera.toggle_stream(should_stream)\r\n\r\n    def is_streaming(self, foreach=False) -> Union[bool, Generator[bool, Any, None]]:\r\n        if foreach:\r\n            return (cam.is_streaming() if isinstance(cam, StreamCamera) else False for cam in self.cameras)\r\n        return self.selected_camera.is_streaming()\r\n\r\n    def get_width(self, foreach=False) -> Union[int, Generator[int, Any, None]]:\r\n        if foreach:\r\n            return (cam.get_width() for cam in self.cameras)\r\n        return self.selected_camera.get_width()\r\n\r\n    def get_height(self, foreach=False) -> Union[int, Generator[int, Any, None]]:\r\n        if foreach:\r\n            return (cam.get_height() for cam in self.cameras)\r\n        return self.selected_camera.get_height()\r\n\r\n    def _set_width(self, width: int, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                if cam is self.selected_camera:\r\n                    cam._set_width(width)\r\n                else:\r\n                    cam.set_frame_size(width, cam.get_height())\r\n        else:\r\n            self.selected_camera._set_width(width)\r\n\r\n    def _set_height(self, height: int, foreach=False):\r\n        if foreach:\r\n            for cam in self.cameras:\r\n                if cam is self.selected_camera:\r\n                    cam._set_height(height)\r\n                else:\r\n                    cam.set_frame_size(cam.get_width(), height)\r\n        else:\r\n            self.selected_camera._set_height(height)\r\n\r\n    def get_fps(self, foreach=False) -> Union[Number, Generator[Number, Any, None]]:\r\n        if foreach:\r\n            return (cam.get_fps() for cam in self.cameras)\r\n        else:\r\n            return self.selected_camera.get_fps()\r\n\r\n    def set_fps(self, fps, foreach=False) -> Union[bool, List[bool]]:\r\n        if foreach:\r\n            return [cam.set_fps(fps) for cam in self.cameras]\r\n        return self.selected_camera.set_fps(fps)\r\n')
	__stickytape_write_module('gbvision/utils/cameras/stream_camera.py',
							  b'import abc\r\nfrom typing import Tuple\r\n\r\nfrom gbvision.constants.types import Frame\r\nfrom gbvision.utils.net.stream_broadcaster import StreamBroadcaster\r\nfrom .camera import Camera\r\n\r\n\r\nclass StreamCamera(Camera, abc.ABC):\r\n    """\r\n    an abstract class that represents a streaming camera\r\n    the streaming camera is very similar to a regular camera, but has an option\r\n    which allows it to stream the frames when it reads them\r\n    """\r\n\r\n    @abc.abstractmethod\r\n    def is_streaming(self) -> bool:\r\n        """\r\n        checks if the camera is currently streaming\r\n\r\n        :return: True if camera is streaming, otherwise False\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def toggle_stream(self, should_stream: bool):\r\n        """\r\n        turn on or off the stream feature\r\n\r\n        :param should_stream: True to activate stream, False to deactivate\r\n        """\r\n\r\n    def read(self):\r\n        ok, frame = self._read()\r\n        self._stream(frame)\r\n        return ok, frame\r\n\r\n    @abc.abstractmethod\r\n    def _read(self) -> Tuple[bool, Frame]:\r\n        """\r\n        unsafely reads from the camera, not to use by the programmer, only by the api\r\n        usually this function is a set to return the value of super(self, CameraClass).read()\r\n\r\n        :return: the return value of Camera.read: (ok, frame)\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def _stream(self, frame: Frame):\r\n        """\r\n        unsafely streams a frame, not to use by the programmer, only by the api\r\n\r\n        :param frame: the frame to stream\r\n        """\r\n\r\n\r\nclass SimpleStreamCamera(StreamCamera, abc.ABC):\r\n    """\r\n    a simple abstract camera that uses a gbvision.StreamBroadcaster to send streams\r\n    this class is abstract and cannot exist on it\'s own, you must inherit from it and implement the _read method\r\n\r\n    for example:\r\n\r\n    Example::\r\n        class USBStreamCamera(SimpleStreamCamera, USBCamera):\r\n            def _read(self) -> Tuple[bool, Frame]:\r\n                return USBCamera.read(self)\r\n\r\n            def __init__(self, broadcaster, port, data=UNKNOWN_CAMERA):\r\n                SimpleStreamCamera.__init__(self, broadcaster)\r\n                USBCamera.__init__(port, data)\r\n    """\r\n\r\n    def __init__(self, broadcaster: StreamBroadcaster, should_stream=False):\r\n        self.__is_streaming = should_stream\r\n        self.stream_broadcaster = broadcaster\r\n\r\n    def is_streaming(self):\r\n        return self.__is_streaming\r\n\r\n    def toggle_stream(self, should_stream: bool):\r\n        self.__is_streaming = should_stream\r\n\r\n    def _stream(self, frame):\r\n        self.stream_broadcaster.send_frame(frame)\r\n')
	__stickytape_write_module('gbvision/utils/net/__init__.py',
							  b'from .async_stream_receiver import AsyncStreamReceiver\r\nfrom .async_tcp_stream_receiver import AsyncTCPStreamReceiver\r\nfrom .async_udp_stream_receiver import AsyncUDPStreamReceiver\r\nfrom .stream_broadcaster import StreamBroadcaster\r\nfrom .stream_receiver import StreamReceiver\r\nfrom .tcp_stream_broadcaster import TCPStreamBroadcaster\r\nfrom .tcp_stream_receiver import TCPStreamReceiver\r\nfrom .udp_stream_broadcaster import UDPStreamBroadcaster\r\nfrom .udp_stream_receiver import UDPStreamReceiver\r\n')
	__stickytape_write_module('gbvision/utils/net/async_stream_receiver.py',
							  b'import abc\r\n\r\nfrom gbvision.utils.net.stream_receiver import StreamReceiver\r\nfrom gbvision.utils.async_readable import AsyncReadable\r\n\r\n\r\nclass AsyncStreamReceiver(AsyncReadable, StreamReceiver, abc.ABC):\r\n    """\r\n    an abstract async tcp stream receiver that receives frames on another thread\r\n    None! when inheriting from this class and another StreamReceiver class, make sure you call the other class\'\r\n    constructor before this class\' constructor, but also make sure you inherit from this class first in order\r\n    """\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        StreamReceiver.__init__(self, *args, **kwargs)\r\n        AsyncReadable.__init__(self)\r\n')
	__stickytape_write_module('gbvision/utils/net/stream_receiver.py',
							  b'import abc\r\nimport pickle\r\nimport cv2\r\nimport struct\r\n\r\nfrom gbvision.constants.types import Frame\r\nfrom gbvision.utils.readable import Readable\r\n\r\n\r\nclass StreamReceiver(Readable, abc.ABC):\r\n    """\r\n    this is an abstract receiver that receives stream from a broadcast receiver\r\n    this class should not be instanced but inherited from\r\n\r\n    :param shape: optional, the shape (x, y) of the sent frame, when set to something other then (0, 0) it overrides\r\n        the fx and fy parameters, when set to (0, 0) it is not used\r\n    :param fx: ratio between width of the read frame to the width of the frame returned, default is 1 (same width)\r\n    :param fy: ratio between height of the read frame to the height of the frame returned,\r\n        default is 1 (same height)\r\n    """\r\n\r\n    def __init__(self, shape=(0, 0), fx: float = 1.0, fy: float = 1.0):\r\n        self.shape = shape\r\n        self.fx = fx\r\n        self.fy = fy\r\n        self.data = b\'\'\r\n        self.payload_size = struct.calcsize("I")\r\n\r\n    @abc.abstractmethod\r\n    def _receive(self) -> bytes:\r\n        """\r\n        reads bytes from the stream and returns them\r\n        the amount of bytes read is the choice of the programmer\r\n        for UDP / RAW formats, a large amount is recommended\r\n        for TCP / TCP like formats, a small amount is recommended\r\n\r\n        """\r\n        pass\r\n\r\n    def _get_frame_data(self) -> bytes:\r\n        """\r\n\r\n        :return:\r\n        """\r\n        while len(self.data) < self.payload_size:\r\n            self.data += self._receive()\r\n        packed_msg_size = self.data[:self.payload_size]\r\n        self.data = self.data[self.payload_size:]\r\n        msg_size = struct.unpack("I", packed_msg_size)[0]\r\n        while len(self.data) < msg_size:\r\n            self.data += self._receive()\r\n        frame_data = self.data[:msg_size]\r\n        self.data = self.data[msg_size:]\r\n        return frame_data\r\n\r\n    def read(self):\r\n        frame_data = self._get_frame_data()\r\n        frame = pickle.loads(frame_data)\r\n        if frame is None:\r\n            return False, None\r\n        frame = cv2.imdecode(frame, -1)\r\n        return True, self._prep_frame(frame)\r\n\r\n    def _prep_frame(self, frame: Frame) -> Frame:\r\n        """\r\n        prepares the frame to be returned and used\r\n        resize and convert to bgr channeled image\r\n        \r\n        :param frame: the frame to be prepared\r\n        :return: the frame after preparations\r\n        """\r\n        if frame is None:\r\n            return frame\r\n        if len(frame.shape) < 3:\r\n            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\r\n        frame = cv2.resize(frame, self.shape, fx=self.fx, fy=self.fy)\r\n        return frame\r\n')
	__stickytape_write_module('gbvision/utils/net/async_tcp_stream_receiver.py',
							  b'from gbvision.utils.net import AsyncStreamReceiver\r\nfrom .tcp_stream_receiver import TCPStreamReceiver\r\n\r\n\r\nclass AsyncTCPStreamReceiver(AsyncStreamReceiver, TCPStreamReceiver):\r\n\r\n    def __init__(self, ip, port, *args, **kwargs):\r\n        TCPStreamReceiver.__init__(self, ip, port, *args, **kwargs)\r\n        AsyncStreamReceiver.__init__(self, *args, **kwargs)\r\n\r\n    def _read(self):\r\n        return TCPStreamReceiver.read(self)\r\n')
	__stickytape_write_module('gbvision/utils/net/tcp_stream_receiver.py',
							  b'import socket\r\n\r\nfrom .stream_receiver import StreamReceiver\r\nfrom gbvision.exceptions.tcp_stream_closed import TCPStreamClosed\r\n\r\n\r\nclass TCPStreamReceiver(StreamReceiver):\r\n    """\r\n    this class uses TCP to receive a stream over the network, the stream is by default set to be MJPEG\r\n    the broadcaster is the server and the receiver is the client\r\n\r\n    :param ip: the IPv4 address of the stream broadcaster, for example \'10.45.90.8\'\r\n    :param port: the port which TCP should use\r\n    """\r\n\r\n    def __init__(self, ip: str, port: int, *args, **kwargs):\r\n        StreamReceiver.__init__(self, *args, **kwargs)\r\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\n        self.server_addr = (ip, port)\r\n        self.socket.connect(self.server_addr)\r\n\r\n    def _receive(self):\r\n        try:\r\n            return self.socket.recv(4096)\r\n        except OSError as e:\r\n            raise TCPStreamClosed() from e\r\n\r\n')
	__stickytape_write_module('gbvision/utils/net/async_udp_stream_receiver.py',
							  b'from gbvision.utils.net import AsyncStreamReceiver\r\nfrom .udp_stream_receiver import UDPStreamReceiver\r\n\r\n\r\nclass AsyncUDPStreamReceiver(AsyncStreamReceiver, UDPStreamReceiver):\r\n\r\n    def __init__(self, port, *args, **kwargs):\r\n        UDPStreamReceiver.__init__(self, port, *args, **kwargs)\r\n        AsyncStreamReceiver.__init__(self, *args, **kwargs)\r\n\r\n    def _read(self):\r\n        return UDPStreamReceiver.read(self)\r\n')
	__stickytape_write_module('gbvision/utils/net/udp_stream_receiver.py',
							  b'import socket\r\n\r\nfrom gbvision.constants.net import LOCAL_SERVER_IP\r\nfrom .stream_receiver import StreamReceiver\r\n\r\n\r\nclass UDPStreamReceiver(StreamReceiver):\r\n    """\r\n    this class uses UDP to receive a stream over the network, the stream is by default set to be MJPEG\r\n    the broadcaster is the client and the receiver is the server\r\n    WARNING: do not use this class to send large images, udp has a limited packet size\r\n\r\n    :param port: the port which udp should use\r\n    """\r\n\r\n    def __init__(self, port: int, *args, **kwargs):\r\n        StreamReceiver.__init__(self, *args, **kwargs)\r\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\r\n        self.server_addr = (LOCAL_SERVER_IP, port)\r\n        self.socket.bind(self.server_addr)\r\n\r\n    def _receive(self) -> bytes:\r\n        return self.socket.recv(2 ** 20)\r\n')
	__stickytape_write_module('gbvision/utils/net/stream_broadcaster.py',
							  b'import abc\r\nimport pickle\r\nimport struct\r\nimport cv2\r\nimport time\r\n\r\nfrom gbvision.constants.math import EPSILON\r\nfrom gbvision.constants.types import Frame\r\n\r\n\r\nclass StreamBroadcaster(abc.ABC):\r\n    """\r\n    this is an abstract broadcaster that sends stream to a broadcast receiver\r\n    this class should not be instanced but inherited from\r\n    creates a new stream broadcaster with all parameters that are used in every broadcaster\r\n    \r\n    :param shape: optional, the shape (x, y) of the sent frame, when set to something other then (0, 0) it overrides\r\n        the fx and fy parameters, when set to (0, 0) it is not used\r\n    :param fx: ratio between width of the given frame to the width of the frame sent, default is 1 (same width)\r\n    :param fy: ratio between height of the given frame to the height of the frame sent, default is 1 (same height)\r\n    :param use_grayscale: boolean indicating if the frame should be converted to grayscale when sent,\r\n        default is False\r\n    :param max_fps: integer representing the maximum fps (frames per second) of the stream, when set to None\r\n        there is no fps limitation, default is None\r\n    :param max_bitrate: Integer that determines the max bitrate of video stream.\r\n        The bitrate is messured with Kbps and default is None.\r\n    """\r\n\r\n    def __init__(self, shape=(0, 0), fx: float = 1.0, fy: float = 1.0, use_grayscale: bool = False,\r\n                 max_fps: int = None, im_encode=\'.jpg\', max_bitrate: int = None):\r\n        self.shape = shape\r\n        self.fx = fx\r\n        self.fy = fy\r\n        self.use_grayscale = use_grayscale\r\n        self.max_fps = max_fps\r\n        self.prev_time = 0.0\r\n        self.im_encode = im_encode\r\n        self.max_bitrate = max_bitrate\r\n\r\n    def send_frame(self, frame: Frame):\r\n        if frame is not None:\r\n            frame = self._prep_frame(frame)\r\n            frame = cv2.imencode(self.im_encode, frame)[1]\r\n        data = pickle.dumps(frame)\r\n        data = struct.pack("I", len(data)) + data\r\n        if self._can_send_frame(data):\r\n            self._send_frame(data)\r\n            self._update_time()\r\n\r\n    @abc.abstractmethod\r\n    def _send_frame(self, frame: bytes):\r\n        """\r\n        unsafely sends the given frame (as pickled data) to the stream receiver\r\n        should not be used by the programmer, only by the api\r\n\r\n        :param frame: the frame to send as pickled data\r\n        """\r\n        pass\r\n\r\n    def _prep_frame(self, frame):\r\n        """\r\n        prepares an image to be sent\r\n        resize and convert the colors of the image by the parameters of the stream broadcaster\r\n\r\n        :param frame: the frame to prepare\r\n        :return: the frame after preparation\r\n        """\r\n        frame = cv2.resize(frame, self.shape, fx=self.fx, fy=self.fy)\r\n        if self.use_grayscale and len(frame.shape) > 2:\r\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n        return frame\r\n\r\n    def _legal_time(self) -> bool:\r\n        """\r\n        checks if at the fps will not pass the max fps limit if an image will be sent at the current moment\r\n        \r\n        :return: true if the image can be sent, false otherwise\r\n        """\r\n        return self.max_fps is None or (time.time() - self.prev_time) * self.max_fps >= 1\r\n\r\n    def _update_time(self):\r\n        """\r\n        updates the previous time a frame was sent, used at the end of send_frame\r\n        """\r\n        self.prev_time = time.time()\r\n\r\n    def _legal_bitrate(self, frame: bytes):\r\n        """\r\n        :return: True if there\'s no bitrate limit or frame bitrate is below max bitrate.  \r\n        """\r\n        return self.max_bitrate is None or len(frame) / (\r\n                (time.time() - self.prev_time + EPSILON) * 1000) <= self.max_bitrate\r\n\r\n    def _can_send_frame(self, frame: bytes):\r\n        if not self._legal_time():\r\n            return False\r\n\r\n        if not self._legal_bitrate(frame):\r\n            return False\r\n\r\n        return True\r\n')
	__stickytape_write_module('gbvision/utils/net/tcp_stream_broadcaster.py',
							  b'import socket\r\n\r\nfrom gbvision.constants.net import LOCAL_SERVER_IP\r\nfrom .stream_broadcaster import StreamBroadcaster\r\nfrom gbvision.exceptions.tcp_stream_closed import TCPStreamClosed\r\n\r\n\r\nclass TCPStreamBroadcaster(StreamBroadcaster):\r\n    """\r\n    this class uses TCP to send a stream over the network, the stream is by default set to be MJPEG\r\n    the broadcaster is the server and the receiver is the client\r\n    \r\n    :param port: the port which TCP will be using\r\n    :param im_encode: the type of image encoding to send over the network, default is .jpg (JPEG)\r\n        for missing parameters, see documentation on StreamBroadcaster\r\n    """\r\n\r\n    def __init__(self, port: int, *args, **kwargs):\r\n        StreamBroadcaster.__init__(self, *args, **kwargs)\r\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\n        self.server_addr = (LOCAL_SERVER_IP, port)\r\n        self.socket.bind(self.server_addr)\r\n        self.socket.listen(10)\r\n        self.socket, addr = self.socket.accept()\r\n\r\n    def _send_frame(self, frame):\r\n        try:\r\n            self.socket.send(frame)\r\n        except IOError as e:\r\n            raise TCPStreamClosed() from e\r\n        self._update_time()\r\n')
	__stickytape_write_module('gbvision/utils/net/udp_stream_broadcaster.py',
							  b'import socket\r\nfrom .stream_broadcaster import StreamBroadcaster\r\n\r\n\r\nclass UDPStreamBroadcaster(StreamBroadcaster):\r\n    """\r\n    this class uses UDP to send a stream over the network, the stream is by default set to be MJPEG\r\n    the broadcaster is the client and the receiver is the server\r\n    WARNING: do not use this class to send large images, udp has a limited packet size\r\n\r\n    :param ip: the IPv4 address of the udp stream receiver, for example \'10.45.90.5\'\r\n    :param port: the port that UDP uses to send packets on\r\n    :param im_encode: the type of image encoding to send over the network, default is \'.jpg\' (JPEG)\r\n    """\r\n\r\n    def __init__(self, ip: str, port: int, *args, **kwargs):\r\n        StreamBroadcaster.__init__(self, *args, **kwargs)\r\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\r\n        self.server_addr = (ip, port)\r\n\r\n    def _send_frame(self, frame):\r\n        self.socket.sendto(frame, self.server_addr)\r\n')
	__stickytape_write_module('gbvision/utils/cameras/empty_camera.py',
							  b'from typing import Tuple, Union\r\n\r\nfrom .camera import Camera\r\nfrom .camera_data import CameraData\r\nfrom gbvision.constants.types import Frame\r\n\r\n\r\nclass EmptyCamera(Camera):\r\n    """\r\n    a camera class used for testing, it cannot be read from but can be used for location finding with finders and game\\\r\n     objects, also used for measuring of distances when using streams instead of cameras to read frames\r\n\r\n    :param data: the camera\'s CameraData object, should match the fake camera\'s data\r\n    :param width: the width of a frame read from the fake camera\r\n    :param height: the height of a frame read from the fake camera\r\n    """\r\n\r\n    def __init__(self, data: CameraData, width: int, height: int):\r\n        self.data = data.copy()\r\n        self.width = width\r\n        self.height = height\r\n\r\n    def release(self):\r\n        pass\r\n\r\n    def is_opened(self) -> bool:\r\n        return False\r\n\r\n    def set_exposure(self, exposure: Union[int, float, bool]) -> bool:\r\n        return False\r\n\r\n    def set_auto_exposure(self, auto: Union[int, float, bool]) -> bool:\r\n        return False\r\n\r\n    def get_data(self) -> CameraData:\r\n        return self.data\r\n\r\n    def get_width(self) -> int:\r\n        return self.width\r\n\r\n    def get_height(self) -> int:\r\n        return self.height\r\n\r\n    def _set_width(self, width: int):\r\n        self.width = width\r\n\r\n    def _set_height(self, height: int):\r\n        self.height = height\r\n\r\n    def read(self) -> Tuple[bool, Frame]:\r\n        return False, None\r\n\r\n    def get_fps(self):\r\n        return 0\r\n\r\n    def set_fps(self, fps):\r\n        return False\r\n')
	__stickytape_write_module('gbvision/utils/cameras/usb_stream_camera.py',
							  b'from typing import Tuple\r\n\r\nfrom gbvision.constants.types import Frame\r\nfrom .stream_camera import SimpleStreamCamera\r\nfrom gbvision.models.cameras import UNKNOWN_CAMERA\r\nfrom .usb_camera import USBCamera\r\n\r\n\r\nclass USBStreamCamera(SimpleStreamCamera, USBCamera):\r\n    """\r\n    a simple USB stream camera\r\n    """\r\n\r\n    def _read(self) -> Tuple[bool, Frame]:\r\n        return USBCamera.read(self)\r\n\r\n    def __init__(self, broadcaster, port, should_stream=False, data=UNKNOWN_CAMERA):\r\n        SimpleStreamCamera.__init__(self, broadcaster, should_stream=should_stream)\r\n        USBCamera.__init__(self, port, data)\r\n')
	__stickytape_write_module('gbvision/models/contours.py',
							  b'from typing import List\r\n\r\nimport cv2\r\n\r\nfrom gbvision.constants.math import EPSILON\r\nfrom gbvision.constants.system import CONTOURS_INDEX\r\nfrom gbvision.constants.types import Contour, Polygon, Point, Frame\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\ndef __mapper(func) -> PipeLine:\r\n    return PipeLine(lambda x: list(map(func, x)))\r\n\r\n\r\n@PipeLine\r\ndef find_contours(frame: Frame) -> List[Contour]:\r\n    """\r\n    finds the contours in a binary frame\r\n\r\n    :param frame: the frame (usually after threshold and denoising)\r\n    :return: a list of all the contours in the frame\r\n    """\r\n    # DO NOT CHANGE THE CHAIN_APPROX_NONE\r\n    # You do not know the damages it may cause\r\n    return cv2.findContours(frame, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[CONTOURS_INDEX]\r\n\r\n\r\n@PipeLine\r\ndef sort_contours(cnts: List[Contour]) -> List[Contour]:\r\n    """\r\n    sorts the list of contours by the contour area\r\n\r\n    :param cnts: the list of contours\r\n    :return: the list given, sorted by area\r\n    """\r\n    return sorted(cnts, key=lambda x: cv2.contourArea(x), reverse=True)\r\n\r\n\r\nclass FilterContours(PipeLine):\r\n    """\r\n    a pipeline factory that receives a list of contours and filters out all contours with an area less then defined\r\n    to the pipeline\r\n\r\n    :param min_area: the minimal area of a contour in order for it to pass the filter\r\n    """\r\n    def __init__(self, min_area: float):\r\n        PipeLine.__init__(self, lambda cnts: filter(lambda c: cv2.contourArea(c) >= min_area, cnts), list)\r\n\r\n\r\nconvex_hull = PipeLine(cv2.convexHull)\r\n\r\nconvex_hull_multiple = __mapper(convex_hull)\r\n\r\n\r\n@PipeLine\r\ndef contour_center(cnt: Contour) -> Point:\r\n    """\r\n    finds the center of the contour\r\n    :param cnt: a contour object\r\n    :return: the center of the contour object\r\n    """\r\n    m = cv2.moments(cnt)\r\n    return int(m[\'m10\'] / (m[\'m00\'] + EPSILON)), int(m[\'m01\'] / (m[\'m00\'] + EPSILON))\r\n\r\n\r\ncontours_centers = __mapper(contour_center)\r\n\r\n# SHAPES\r\n\r\ncontours_to_rects = __mapper(cv2.boundingRect)\r\n\r\n\r\n@PipeLine\r\ndef sort_rects(rects):\r\n    return list(sorted(rects, key=lambda x: x[2] * x[3], reverse=True))\r\n\r\n\r\ncontours_to_rects_sorted = contours_to_rects + sort_rects\r\n\r\ncontours_to_circles = __mapper(cv2.minEnclosingCircle)\r\n\r\n\r\n@PipeLine\r\ndef sort_circles(circs):\r\n    return list(sorted(circs, key=lambda x: x[1], reverse=True))\r\n\r\n\r\ncontours_to_circles_sorted = contours_to_circles + sort_circles\r\n\r\ncontours_to_rotated_rects = __mapper(cv2.minAreaRect)\r\n\r\n\r\n@PipeLine\r\ndef sort_rotated_rects(rects):\r\n    return list(sorted(rects, key=lambda x: x[1][0] * x[1][1], reverse=True))\r\n\r\n\r\ncontours_to_rotated_rects_sorted = contours_to_rotated_rects + sort_rotated_rects\r\n\r\n\r\n@PipeLine\r\ndef contours_to_ellipses(cnts):\r\n    cnts = filter(lambda x: len(x) >= 5, cnts)\r\n    # ellipse must get contours of at least five points\r\n    return list(map(cv2.fitEllipse, cnts))\r\n\r\n\r\nsort_ellipses = sort_rotated_rects\r\n\r\ncontours_to_ellipses_sorted = contours_to_ellipses + sort_ellipses\r\n\r\n\r\n@PipeLine\r\ndef contours_to_polygons(cnts):\r\n    """\r\n    performs approxPolyDP algorithm on a list of contours\r\n\r\n    :param cnts: the list of contours\r\n    :return: a list of polygons from the contours\r\n    """\r\n    arc_lengts = map(lambda cnt: 0.05 * cv2.arcLength(cnt, True), cnts)\r\n    return list(map(lambda cnt: cv2.approxPolyDP(cnt, next(arc_lengts), True), cnts))\r\n\r\n\r\n@PipeLine\r\ndef fix_contours_shape(cnts: List[Contour]) -> List[Polygon]:\r\n    """\r\n    fixes the contours to a usable shape\r\n    the shape of the contours is a list of tuples of integers/floats, where each tuple is a point\r\n    an example of two rectangles represented with this shape will be:\r\n    [[(0, 0), (0, 2), (1, 2), (1, 0)],\r\n    [(5, 4), (7, 4), (7, 9), (9, 5)]]\r\n    \r\n    :param cnts: the contours / polygons list whose shape should be fixed\r\n    :return: a list of all the contours with the fixed shape\r\n    """\r\n    cnts = map(lambda polydp: map(lambda x: x[0], polydp), cnts)\r\n    return list(map(lambda polydp: list(map(tuple, polydp)), cnts))\r\n\r\n\r\nsort_polygons = sort_contours\r\n\r\npolygon_center = contour_center\r\n\r\npolygons_centers = contours_centers\r\n')
	__stickytape_write_module('gbvision/utils/pipeline.py',
							  b'from typing import Any, Callable\r\nimport functools\r\n\r\n\r\nclass PipeLine:\r\n    """\r\n    a class representing a pipeline of function\r\n    each function receives one input, which is the output of the previous function in the pipeline\r\n    pipelines are great for representing a long computer vision function (which is why such functions\r\n    are called pipelines).\r\n    the PipeLine class can also be used as a function decorator\r\n    for example, creating a pipeline that adds 1 to it\'s output can be done in two ways:\r\n    Example::\r\n        inc = PipeLine(lambda x: x + 1)\r\n        three = inc(2)\r\n        \r\n    or\r\n    Example::\r\n        @PipeLine\r\n        def inc(x):\r\n            return x + 1\r\n        three = inc(2)\r\n\r\n\r\n    You can create a PipeLine from multiple functions:\r\n    Example::\r\n        open_and_read_file = PipeLine(open, lambda x: x.read())\r\n        text = open_and_read_file("file.txt")\r\n            \r\n    You can also inherit from the PipeLine class to make a PipeLine factory:\r\n    Example::\r\n        class Adder(PipeLine):\r\n            def __init__(self, num):\r\n                self.num = num\r\n                PipeLine.__init__(self, self.adding_func)\r\n            def adding_func(self, item):\r\n                return item + self.num\r\n\r\n    You can also do it like this:\r\n    Example::\r\n        class Adder(PipeLine):\r\n            def __init__(self, num):\r\n                def adding_func(item):\r\n                    return item + num\r\n\r\n                PipeLine.__init__(self, adding_func)\r\n\r\n    You can use combine a few PipeLines together to create function composition:\r\n    Example::\r\n        multiply_by_2_then_add_3 = PipeLine(lambda x: x * 2) + PipeLine(lambda x: x + 3)\r\n\r\n    :param functions: a tuple of functions to run one after the other as a pipeline\r\n    """\r\n\r\n    def __init__(self, *functions: Callable[[Any], Any]):\r\n        self.functions = list(functions)\r\n\r\n    def __call__(self, image):\r\n        """\r\n        activate this pipeline and return the result\r\n\r\n        :param image: the input to the first function in the pipeline (also the input to the entire pipeline) \\\r\n        doesn\'t have to be an image, can be anything\r\n        :return: the output of the last function in the pipeline, can be data type\r\n        """\r\n        return functools.reduce(lambda x, f: f(x), self.functions, image)\r\n\r\n    def __add__(self, other):\r\n        """\r\n        creates a new pipeline which uses the output of this pipeline as input to the other pipeline\r\n\r\n        :param other: the second pipeline\r\n        :return: a new pipeline, and calling this pipeline with the parameter image is similar to \\\r\n        performing other(self(image))\r\n        """\r\n        if isinstance(other, PipeLine):\r\n            return PipeLine(*self.functions + other.functions)\r\n        return PipeLine(*self.functions + [other])\r\n\r\n    def __radd__(self, other):\r\n        """\r\n        adds this PipeLine to another function that isn\'t a PipeLine\r\n\r\n        :param other: the function\r\n        :return: a new PipeLine which performs self(other(image)) on the parameter image\r\n        """\r\n        return PipeLine(other) + self\r\n\r\n    def __getitem__(self, item):\r\n        """\r\n        gets the function at index item\r\n\r\n        :param item: the index\r\n        :return: the item\r\n        """\r\n        return self.functions[item]\r\n\r\n    def __setitem__(self, key, value):\r\n        """\r\n        sets the function at index key to the new function value\r\n\r\n        :param key: the index\r\n        :param value: the new function\r\n        """\r\n        self.functions[key] = value\r\n\r\n    def __iter__(self):\r\n        """\r\n        :return: an iterator that iterates through all functions in this pipeline\r\n        """\r\n        return iter(self.functions)\r\n')
	__stickytape_write_module('gbvision/utils/tracker.py',
							  b'import cv2\r\n\r\n\r\nclass __EmptyTracker:\r\n    def __init__(self):\r\n        self.__rect = None\r\n\r\n    def init(self, frame, rect):\r\n        self.__rect = rect\r\n        return True\r\n\r\n    def update(self, frame):\r\n        return True, self.__rect\r\n\r\n\r\ntry:\r\n    TRACKER_ALGORITHMS = {\r\n        "BOOSTING": cv2.TrackerBoosting_create,\r\n        "MIL": cv2.TrackerMIL_create,\r\n        "KCF": cv2.TrackerKCF_create,\r\n        "TLD": cv2.TrackerTLD_create,\r\n        "MEDIANFLOW": cv2.TrackerMedianFlow_create,\r\n        "GOTURN": cv2.TrackerGOTURN_create,\r\n        "MOSSE": cv2.TrackerMOSSE_create,\r\n        "CSRT": cv2.TrackerCSRT_create,\r\n        "EMPTY": __EmptyTracker\r\n    }\r\nexcept AttributeError:\r\n    import sys\r\n    print("[WARN] no trackers in your version of opencv, you may only use the empty tracker", file=sys.stderr)\r\n    TRACKER_ALGORITHMS = {\r\n        "EMPTY": __EmptyTracker\r\n    }\r\n\r\n\r\nclass Tracker:\r\n    """\r\n    a tracker object that tracks a rectangle in a video using an opencv tracking algorithm\r\n\r\n    :param tracker_type: Tracker algorithm taken from this list: BOOSTING, MIL, KCF, TLD, MEDIANFLOW,\r\n        GOTURN, MOSSE, CSRT, EMPTY. (Default is EMPTY)\r\n    """\r\n\r\n    TRACKER_TYPE_BOOSTING = \'BOOSTING\'\r\n    TRACKER_TYPE_MIL = \'MIL\'\r\n    TRACKER_TYPE_KCF = \'KCF\'\r\n    TRACKER_TYPE_TLD = \'TLD\'\r\n    TRACKER_TYPE_MEDIANFLOW = \'MEDIANFLOW\'\r\n    TRACKER_TYPE_GOTURN = \'GOTURN\'\r\n    TRACKER_TYPE_MOSSE = \'MOSSE\'\r\n    TRACKER_TYPE_CSRT = \'CSRT\'\r\n    TRACKER_TYPE_EMPTY = \'EMPTY\'\r\n\r\n    def __init__(self, tracker_type="EMPTY"):\r\n        tracker_type = tracker_type.upper()\r\n        assert tracker_type in TRACKER_ALGORITHMS\r\n        self.tracker = TRACKER_ALGORITHMS[tracker_type]()\r\n        self.tracker_type = tracker_type\r\n\r\n    def init(self, frame, rect):\r\n        """\r\n        Initlize the tracker\r\n\r\n        :param frame: The frame\r\n        :param rect: Given rectangle\r\n        :return: True if initialization went succesfully, false otherwise\r\n        """\r\n        return self.tracker.init(frame, tuple([int(max(x, 0)) for x in rect]))\r\n\r\n    def update(self, frame):\r\n        """\r\n        Get the rect location in new frame\r\n\r\n        :param frame: the frame\r\n        :return: The location of the rect in new frame\r\n\r\n        """\r\n        return self.tracker.update(frame)[1]\r\n')
	__stickytape_write_module('gbvision/utils/continuity/__init__.py',
							  b'from .continues_circle import ContinuesCircle\r\nfrom .continues_rect import ContinuesRect\r\nfrom .continues_rotated_rect import ContinuesRotatedRect\r\nfrom .continues_shape import ContinuesShape\r\nfrom .continues_shape_wrapper import ContinuesShapeWrapper\r\n')
	__stickytape_write_module('gbvision/utils/continuity/continues_circle.py',
							  b'import numpy as np\r\n\r\nfrom gbvision.models.shapes import circle_collision\r\nfrom gbvision.constants.types import Rect, Circle\r\nfrom .continues_shape import ContinuesShape\r\nfrom gbvision.utils.shapes.base_circle import BaseCircle\r\n\r\n\r\nclass ContinuesCircle(ContinuesShape):\r\n    """\r\n    An implementation of ContinuesShape to circles.\r\n    used to try and check whether two circles are indeed the same one.\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseCircle\r\n\r\n    def __init__(self, shape: Circle, *args, **kwargs):\r\n        ContinuesShape.__init__(self, shape, *args, **kwargs)\r\n\r\n    def _shape_collision(self, shape) -> bool:\r\n        return circle_collision(self._shape, shape)\r\n\r\n    @staticmethod\r\n    def _from_bounding_rect(bounding_rect) -> Circle:\r\n        circle = (\r\n            (bounding_rect[0] + bounding_rect[2] / 2, bounding_rect[1] + bounding_rect[3] / 2),\r\n            (bounding_rect[3] + bounding_rect[2]) / 4)\r\n        return circle\r\n\r\n    @staticmethod\r\n    def _to_bounding_rect(shape) -> Rect:\r\n        rect = (shape[0][0] - shape[1], shape[0][1] - shape[1], 2 * shape[1], 2 * shape[1])\r\n        return rect\r\n')
	__stickytape_write_module('gbvision/models/shapes.py',
							  b'from typing import List, Callable\r\n\r\nfrom gbvision.constants.types import RotatedRect, Polygon, Rect, Circle, Shape\r\nfrom gbvision.utils.pipeline import PipeLine\r\nimport numpy as np\r\nimport cv2\r\n\r\n\r\nclass __InnerShapeFilter(PipeLine):\r\n    """\r\n    filters out all the shapes that are colliding with shapes with a lower (smaller) index\r\n    maps from List[Shape] to List[Shape], where the output list is the input list without the colliding shapes\r\n    usually used on a sorted list, to remove any shape that is inside another shape\r\n\r\n    """\r\n\r\n    def __init__(self, collision_func: Callable[[Shape, Shape], bool]):\r\n        def _filter(shapes: List[Shape]) -> List[Shape]:\r\n            filtered_shapes = []\r\n            for i, shape in enumerate(shapes):\r\n                shape_invalid = False\r\n                for j in range(i):\r\n                    shape_invalid = collision_func(shape, shapes[j])\r\n                    if shape_invalid:\r\n                        break\r\n                if not shape_invalid:\r\n                    filtered_shapes.append(shape)\r\n            return filtered_shapes\r\n\r\n        PipeLine.__init__(self, _filter)\r\n\r\n\r\ndef circle_collision(circ1: Circle, circ2: Circle) -> bool:\r\n    """\r\n    detects if two circles are colliding\r\n\r\n    :param circ1: the first circle\r\n    :param circ2: the second circle\r\n    :return: True if circles are colliding, False otherwise\r\n    """\r\n    center1, r1 = circ1\r\n    center2, r2 = circ2\r\n    return (center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2 < (r1 + r2) ** 2\r\n\r\n\r\nfilter_inner_circles = __InnerShapeFilter(circle_collision)\r\n\r\n\r\ndef rect_collision(r1: Rect, r2: Rect) -> bool:\r\n    """\r\n    detects if two rects are colliding\r\n\r\n    :param r1: the first rect\r\n    :param r2: the second rect\r\n    :return: True if the rects are colliding, False otherwise\r\n    """\r\n    return not (r1[0] > r2[0] + r2[2] or\r\n                r1[0] + r1[2] < r1[0] or\r\n                r1[1] > r2[1] + r2[3] or\r\n                r1[1] + r1[3] < r2[1])\r\n\r\n\r\nfilter_inner_rects = __InnerShapeFilter(rect_collision)\r\n\r\n\r\ndef convex_shape_collision(shape1: Polygon, shape2: Polygon) -> bool:\r\n    """\r\n    detects collision between two convex shapes\r\n    Note: if you are uncertain if a shape is convex, use convex_hull on it, it will make it convex\r\n\r\n    :param shape1: the first shape, as a contour\r\n    :param shape2: the second shape, as a contour\r\n    :return: True if the shapes are colliding, False otherwise\r\n    """\r\n    shape1, shape2 = np.array(shape1), np.array(shape2)\r\n    shape1 = shape1.reshape(shape1.size // 2, 2)\r\n    shape2 = shape2.reshape(shape1.size // 2, 2)\r\n\r\n    projection_axises = []\r\n\r\n    negation_array = np.array([-1.0, 1.0])\r\n\r\n    for i in range(len(shape1)):\r\n        projection_axises.append(shape1[(i + 1) % len(shape1)] - shape1[i])\r\n    for i in range(len(shape2)):\r\n        projection_axises.append(shape2[(i + 1) % len(shape2)] - shape2[i])\r\n\r\n    for i in range(len(projection_axises)):\r\n        projection_axises[i] = projection_axises[i][::-1] * negation_array\r\n\r\n    for axis in projection_axises:\r\n        proj1 = []\r\n        for vertix in shape1:\r\n            proj1.append(vertix.dot(axis))\r\n        proj1 = min(proj1), max(proj1)\r\n\r\n        proj2 = []\r\n        for vertix in shape2:\r\n            proj2.append(vertix.dot(axis))\r\n        proj2 = min(proj2), max(proj2)\r\n\r\n        if proj1[0] > proj2[1] or proj2[0] > proj1[1]:\r\n            return False\r\n\r\n    return True\r\n\r\n\r\nfilter_inner_convex_shapes = __InnerShapeFilter(convex_shape_collision)\r\n\r\n\r\ndef rotated_rect_collision(rr1: RotatedRect, rr2: RotatedRect) -> bool:\r\n    """\r\n    detects if two rotated rects are colliding\r\n\r\n    :param rr1: the first rotated rect\r\n    :param rr2: the second rotated rect\r\n    :return: True if the shapes are colliding, False otherwise\r\n    """\r\n    return convex_shape_collision(cv2.boxPoints(rr1), cv2.boxPoints(rr2))\r\n\r\n\r\nfilter_inner_rotated_rects = __InnerShapeFilter(rotated_rect_collision)\r\n')
	__stickytape_write_module('gbvision/utils/continuity/continues_shape.py',
							  b'import abc\r\n\r\nfrom gbvision.constants.types import Rect, Number, Frame, Point, Shape\r\nfrom gbvision.utils.shapes.base_shape import BaseShapeType\r\nfrom gbvision.utils.tracker import Tracker\r\n\r\n\r\nclass ContinuesShape(abc.ABC):\r\n    """\r\n    An abstract class who\'s target is to determine in which case two shapes are describing\r\n    the same object, and by that represent a shape in a continues matter.\r\n\r\n    in case that no shape matching the object is found then the tracker is deployed by using force_update.\r\n\r\n    :param shape: the shape to track with continuity\r\n    :param frame: the frame from which the shape was taken\r\n    :param tracker: optional, a tracker used to track the object if it wasn\'t found with continuity (default is an empty tracker)\r\n    :param max_area_ratio: the maximum ration between areas of the current shape and another shape \\\r\n     so that they can be thought of as the same, default is 2.0\r\n    :param max_distance_ratio: the maximum ratio between the sum of areas of this shape and another and their distance, default is 0.1\r\n    """\r\n\r\n    def __init__(self, shape, frame: Frame, tracker: Tracker = None, max_area_ratio=2.0,\r\n                 max_distance_ratio=2.0):  # initialization method of the abstract class\r\n        assert max_area_ratio > 1.0  # sets maximum area ratio as 1\r\n        self._shape = shape  # shape describing the object\r\n        self._count = 0  # the count of how many frames the object cannot be found\r\n        self._tracker = Tracker() if tracker is None else tracker  # Tracker setup in case object is not found\r\n        self._tracker.init(frame, self._to_bounding_rect(shape))\r\n        self.max_area_ratio = max_area_ratio  # setting the maximum bound to which the area difference between the\r\n        # two shapes can be withstanded until it declared as not the same object\r\n        self.max_distance_ratio = max_distance_ratio  # same goes here except it refers to distance between shapes\r\n\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def _base_shape() -> BaseShapeType:\r\n        """\r\n        returns the base shape matching this continues shape\r\n\r\n        :return: the base shape (a class that inherits from BaseShape)\r\n        """\r\n\r\n    def _shape_collision(self, shape: Shape) -> bool:\r\n        return self._base_shape().shape_collision(self._shape, shape)\r\n\r\n    @classmethod\r\n    def _shape_area(cls, shape: Shape) -> Number:\r\n        return cls._base_shape().shape_area(shape)\r\n\r\n    @classmethod\r\n    def _shape_center(cls, shape: Shape) -> Point:\r\n        return cls._base_shape().shape_center(shape)\r\n\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def _from_bounding_rect(bounding_rect: Rect) -> Shape:\r\n        """\r\n        a function which finds a shape according to its bounding rectangle\r\n        :param: the rectangle bounding the shape\r\n        :return: a shape that is bound by the bounding rect\r\n        """\r\n\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def _to_bounding_rect(shape: Shape) -> Rect:\r\n        """\r\n        finds a rectangle bounding a shape\r\n        :param shape: the shape\'s bounding rectangle you wish to find\r\n        :return: a rectangle which bounds the shape given\r\n        """\r\n\r\n    def _shape_square_distance(self, other_shape: Shape) -> Number:\r\n        """\r\n        a method which finds the distance between the centers of the object shape and another one\r\n        :param other_shape: the other shape you want to check the distance to\r\n        :return: the distance between the shape squared in order to save computing of square root (pythagorean theorem)\r\n        """\r\n        self_center, other_center = self._shape_center(self._shape), self._shape_center(other_shape)\r\n        return (other_center[0] - self_center[0]) ** 2 + \\\r\n               (other_center[1] - self_center[1]) ** 2\r\n\r\n    def _is_legal(self, shape: Shape) -> bool:\r\n        """\r\n        checks a variety of different relations between to shapes to determine whether it describes the same object or not\r\n        :param shape: the other shape comparing to the current one\r\n        :return: true or false, same or different\r\n        """\r\n        if self._shape_collision(shape):\r\n            if 1.0 / self.max_area_ratio <= self._shape_area(self._shape) / self._shape_area(\r\n                    shape) <= self.max_area_ratio:\r\n                if self._shape_square_distance(shape) <= (\r\n                        self._shape_area(self._shape) + self._shape_area(shape)) * self.max_distance_ratio:\r\n                    return True\r\n        return False\r\n\r\n    def get(self) -> Shape:\r\n        """\r\n        retrieve the shape that this continues shape tracks\r\n\r\n        :return: this continues shape\'s inner shape\r\n        """\r\n        return self._shape\r\n\r\n    def update(self, shape: Shape, frame: Frame) -> bool:\r\n        """\r\n        an annual check updating the location and data of the object\r\n        :param shape: the shape suspect as the same object\r\n        :param frame: the frame on which the suspect shape is\r\n        :return: true or false, same shape, not the same shape\r\n        """\r\n        if self._is_legal(shape):\r\n            self._shape = shape\r\n            self._count = 0\r\n            self._tracker.init(frame, self._to_bounding_rect(shape))\r\n            return True\r\n        return False\r\n\r\n    def update_forced(self, frame: Frame):\r\n        """\r\n        an update which happens when you lost the shape with continuity\r\n        :param frame: the frame on which opencv2 tracking is happening\r\n        """\r\n        self._shape = self._from_bounding_rect(self._tracker.update(frame))\r\n        self._count += 1\r\n\r\n    def is_lost(self, max_count: int) -> bool:\r\n        """\r\n        check if it has been too long (more that max_count frames) since you last saw the object\r\n\r\n        :param max_count:the maximum amount of frames tolerable before the shape is declared lost, None is infinity\r\n        :return: lost or not\r\n        """\r\n        return max_count is not None and self._count > max_count\r\n')
	__stickytape_write_module('gbvision/utils/shapes/__init__.py',
							  b'from .base_shape import BaseShape\r\nfrom .base_circle import BaseCircle\r\nfrom .base_rect import BaseRect\r\nfrom .base_convex_polygon import BaseConvexPolygon\r\nfrom .base_contour import BaseContour\r\nfrom .base_rotated_rect import BaseRotatedRect\r\nfrom .base_polygon import BasePolygon\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_shape.py',
							  b'import abc\r\nfrom typing import Type, List\r\n\r\nimport numpy as np\r\n\r\nfrom gbvision.constants.types import Shape, Number, Rect, Point\r\n\r\n\r\nclass BaseShape(abc.ABC):\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def shape_collision(shape1: Shape, shape2: Shape) -> bool:\r\n        """\r\n        checks if the two shapes are colliding\r\n\r\n        :param shape1: the first shape\r\n        :param shape2: the second shape\r\n        :return: True if the shapes are colliding, False otherwise\r\n        """\r\n\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def shape_area(shape: Shape) -> Number:\r\n        """\r\n        calculates the area of the shape\r\n\r\n        :param shape: the shape\r\n        :return: the area of the shape\r\n        """\r\n\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def shape_center(shape: Shape) -> Point:\r\n        """\r\n        calculates the center-of-mass of the shape\r\n\r\n        :param shape: the shape\r\n        :return: the center of the shape\r\n        """\r\n\r\n    @classmethod\r\n    def shape_root_area(cls, shape: Shape) -> Number:\r\n        """\r\n        calculates the square root of the area of the shape\r\n        default is the square root of cls.shape_area, but it can be overridden in case there is a simpler way\\\r\n         (for example for circles)\r\n\r\n        :param shape: the shape\r\n        :return: the square root of the area of the shape\r\n        """\r\n        return np.sqrt(cls.shape_area(shape))\r\n\r\n    @classmethod\r\n    def sort_shapes(cls, shapes: List[Shape]) -> List[Shape]:\r\n        """\r\n        sorts the list of shapes by area, should be overridden to use area root in case it\'s better\r\n        doesn\'t modify the given list, returns a new list\r\n\r\n        :param shapes: the list of shapes to sort\r\n        :return: a sorted copy of the list of shapes\r\n        """\r\n        return sorted(shapes, key=cls.shape_area, reverse=True)\r\n\r\n    @classmethod\r\n    def filter_inner_shapes(cls, shapes: List[Shape]) -> List[Shape]:\r\n        """\r\n        filters out all shapes that are colliding with a shape with a smaller index in the given list\r\n        returns a list of all shapes that aren\'t colliding\r\n\r\n        :param shapes: the list of shapes\r\n        :return: the filtered list of shapes\r\n        """\r\n        filtered_shapes = []\r\n        for i, shape in enumerate(shapes):\r\n            shape_invalid = False\r\n            for j in range(i):\r\n                shape_invalid = cls.shape_collision(shape, shapes[j])\r\n                if shape_invalid:\r\n                    break\r\n            if not shape_invalid:\r\n                filtered_shapes.append(shape)\r\n        return filtered_shapes\r\n\r\n\r\nBaseShapeType = Type[BaseShape]\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_circle.py',
							  b'from typing import List\r\n\r\nfrom gbvision.constants.math import SQRT_PI\r\n\r\nfrom .base_shape import BaseShape\r\nfrom gbvision.constants.types import Circle, Number, Point\r\nfrom gbvision.models.shapes import circle_collision\r\n\r\n\r\nclass BaseCircle(BaseShape):\r\n    @staticmethod\r\n    def shape_center(shape: Circle) -> Point:\r\n        return shape[0]\r\n\r\n    @staticmethod\r\n    def shape_collision(shape1: Circle, shape2: Circle) -> bool:\r\n        return circle_collision(shape1, shape2)\r\n\r\n    @classmethod\r\n    def shape_area(cls, shape: Circle) -> Number:\r\n        return cls.shape_root_area(shape) ** 2\r\n\r\n    @classmethod\r\n    def shape_root_area(cls, shape: Circle) -> Number:\r\n        return shape[1] * SQRT_PI\r\n\r\n    @classmethod\r\n    def sort_shapes(cls, shapes: List[Circle]):\r\n        return sorted(shapes, key=cls.shape_root_area)\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_rect.py',
							  b'from .base_shape import BaseShape\r\nfrom gbvision.constants.types import Rect, Number, Point\r\nfrom gbvision.models.shapes import rect_collision\r\n\r\n\r\nclass BaseRect(BaseShape):\r\n    @staticmethod\r\n    def shape_center(shape: Rect) -> Point:\r\n        return shape[0] + (shape[2] / 2), shape[1] + (shape[3] / 2)\r\n\r\n    @staticmethod\r\n    def shape_collision(shape1: Rect, shape2: Rect) -> bool:\r\n        return rect_collision(shape1, shape2)\r\n\r\n    @classmethod\r\n    def shape_area(cls, shape: Rect) -> Number:\r\n        return shape[2] * shape[3]\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_convex_polygon.py',
							  b'from .base_polygon import BasePolygon\r\nfrom gbvision.constants.types import Polygon\r\nfrom gbvision.models.shapes import convex_shape_collision\r\n\r\n\r\nclass BaseConvexPolygon(BasePolygon):\r\n\r\n    @staticmethod\r\n    def shape_collision(shape1: Polygon, shape2: Polygon) -> bool:\r\n        return convex_shape_collision(shape1, shape2)\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_polygon.py',
							  b'import cv2\r\n\r\nfrom .base_shape import BaseShape\r\nfrom gbvision.constants.types import Polygon, Number, Point\r\nfrom gbvision.models.contours import contour_center\r\n\r\n\r\nclass BasePolygon(BaseShape):\r\n    @staticmethod\r\n    def shape_area(shape: Polygon) -> Number:\r\n        return cv2.contourArea(shape)\r\n\r\n    @staticmethod\r\n    def shape_center(shape: Polygon) -> Point:\r\n        return contour_center(shape)\r\n\r\n    @staticmethod\r\n    def shape_collision(shape1: Polygon, shape2: Polygon) -> bool:\r\n        return NotImplemented\r\n\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_contour.py',
							  b'import cv2\r\n\r\nfrom .base_shape import BaseShape\r\nfrom gbvision.constants.types import Contour, Number, Point\r\nfrom gbvision.models.contours import contour_center\r\n\r\n\r\nclass BaseContour(BaseShape):\r\n    @staticmethod\r\n    def shape_area(shape: Contour) -> Number:\r\n        return cv2.contourArea(shape)\r\n\r\n    @staticmethod\r\n    def shape_center(shape: Contour) -> Point:\r\n        return contour_center(shape)\r\n\r\n    @staticmethod\r\n    def shape_collision(shape1: Contour, shape2: Contour) -> bool:\r\n        return NotImplemented\r\n\r\n')
	__stickytape_write_module('gbvision/utils/shapes/base_rotated_rect.py',
							  b'from .base_shape import BaseShape\r\nfrom gbvision.constants.types import RotatedRect, Number, Point\r\nfrom gbvision.models.shapes import rotated_rect_collision\r\n\r\n\r\nclass BaseRotatedRect(BaseShape):\r\n    @staticmethod\r\n    def shape_center(shape: RotatedRect) -> Point:\r\n        return shape[0]\r\n\r\n    @staticmethod\r\n    def shape_collision(shape1: RotatedRect, shape2: RotatedRect) -> bool:\r\n        return rotated_rect_collision(shape1, shape2)\r\n\r\n    @classmethod\r\n    def shape_area(cls, shape: RotatedRect) -> Number:\r\n        return shape[1][0] * shape[1][1]\r\n')
	__stickytape_write_module('gbvision/utils/continuity/continues_rect.py',
							  b'from copy import deepcopy\r\n\r\nfrom gbvision.models.shapes import rect_collision\r\nfrom gbvision.constants.types import Rect\r\nfrom .continues_shape import ContinuesShape\r\nfrom gbvision.utils.shapes.base_rect import BaseRect\r\n\r\n\r\nclass ContinuesRect(ContinuesShape):\r\n    """\r\n    An implementation of ContinuesShape to rectangles.\r\n    used to try and check whether two rectangles are indeed the same one.\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseRect\r\n\r\n    def __init__(self, shape: Rect, *args, **kwargs):\r\n        ContinuesShape.__init__(self, shape=shape, *args, **kwargs)\r\n\r\n    def _shape_collision(self, shape) -> bool:\r\n        return rect_collision(self._shape, shape)\r\n\r\n    @staticmethod\r\n    def _from_bounding_rect(bounding_rect: Rect):\r\n        return deepcopy(bounding_rect)\r\n\r\n    @staticmethod\r\n    def _to_bounding_rect(rect: Rect) -> Rect:\r\n        return deepcopy(rect)\r\n')
	__stickytape_write_module('gbvision/utils/continuity/continues_rotated_rect.py',
							  b'import numpy as np\r\n\r\nfrom gbvision.models.shapes import rotated_rect_collision\r\nfrom gbvision.constants.types import RotatedRect, Rect\r\nfrom .continues_shape import ContinuesShape\r\nfrom gbvision.utils.shapes.base_rotated_rect import BaseRotatedRect\r\n\r\n\r\nclass ContinuesRotatedRect(ContinuesShape):\r\n    """\r\n    An implementation of ContinuesShape to rotated rectangles.\r\n    used to try and check whether two rotated rectangles are indeed the same one.\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseRotatedRect\r\n\r\n    def __init__(self, shape: RotatedRect, *args, **kwargs):\r\n        ContinuesShape.__init__(self, shape=shape, *args, **kwargs)\r\n\r\n    def _shape_collision(self, shape) -> bool:\r\n        return rotated_rect_collision(self._shape, shape)\r\n\r\n    @staticmethod\r\n    def _from_bounding_rect(bounding_rect: Rect) -> RotatedRect:\r\n        # assuming the tilting angle is 0\r\n        return ((bounding_rect[0] - bounding_rect[2]) / 2, (bounding_rect[1] + bounding_rect[3] / 2)), \\\r\n               bounding_rect[2:4], 0\r\n\r\n    @staticmethod\r\n    def _to_bounding_rect(rotated_rect: RotatedRect) -> Rect:\r\n        x = rotated_rect[0][0]\r\n        y = rotated_rect[0][1]\r\n        w = rotated_rect[1][0]\r\n        h = rotated_rect[1][1]\r\n        a = np.deg2rad(rotated_rect[2])\r\n\r\n        bound_w = w * np.cos(a) + h * np.sin(a)\r\n        bound_h = h * np.cos(a) + w * np.sin(a)\r\n        bound_x = x - bound_w / 2\r\n        bound_y = y - bound_h / 2\r\n        return bound_x, bound_y, bound_w, bound_h\r\n')
	__stickytape_write_module('gbvision/utils/continuity/continues_shape_wrapper.py',
							  b'from typing import List, Dict, Callable, Union\r\n\r\nfrom gbvision.constants.types import Frame, Shape\r\nfrom gbvision.utils.continuity import ContinuesCircle\r\nfrom gbvision.utils.continuity.continues_rect import ContinuesRect\r\nfrom gbvision.utils.continuity import ContinuesRotatedRect\r\nfrom gbvision.utils.continuity import ContinuesShape\r\nfrom gbvision.utils.tracker import Tracker\r\n\r\n_CONTINUES_SHAPE_TYPES = {\r\n    \'CIRCLE\': ContinuesCircle,\r\n    \'RECT\': ContinuesRect,\r\n    \'ROTATED_RECT\': ContinuesRotatedRect\r\n\r\n}\r\n\r\n\r\nclass ContinuesShapeWrapper:\r\n    """\r\n    an object that tracks several shapes in a frame using continuity\r\n\r\n    :param shapes: a list of shapes to track using continuity (must be of the same shape)\r\n    :param frame: the frame from which the shapes were found\r\n    :param finding_pipeline: a function that finds the shapes in a given frame and returns a list of them (order irrelevant)\r\n    :param shape_type: the type of the shape, can be either \'CIRCLE\', \'RECT\', or \'ROTATED_RECT\', default is \'RECT\', can also be a class that inherits from ContinuesShape\r\n    :param tracker_type: the type of the trackers to use, default is \'EMPTY\'\r\n    :param shape_lifespan: the maximum amount of frames for a shape to not be found until it is considered lost\r\n    :param track_new: indicates whether to track new shapes that were un-tracked so far or ignore them, default is False (ignore)\r\n    :param args: additional arguments for continues shape constructor \r\n    :param kwargs: additional keyword arguments for continues shape constructor\r\n    """\r\n\r\n    SHAPE_TYPE_CIRCLE = \'CIRCLE\'\r\n    SHAPE_TYPE_RECT = \'RECT\'\r\n    SHAPE_TYPE_ROTATED_RECT = \'ROTATED_RECT\'\r\n\r\n    def __init__(self, shapes: List[Shape], frame: Frame, finding_pipeline: Callable[[Frame], List[Shape]],\r\n                 shape_type: Union[str, type] = \'RECT\', tracker_type=Tracker.TRACKER_TYPE_EMPTY,\r\n                 shape_lifespan: int = None, track_new=False, *args, **kwargs):\r\n\r\n        if shape_type in _CONTINUES_SHAPE_TYPES:\r\n            shape_type = shape_type.upper()\r\n            self.shape_type = _CONTINUES_SHAPE_TYPES[shape_type]\r\n        else:\r\n            self.shape_type = shape_type\r\n        self.tracker_type = tracker_type\r\n        self.shape_lifespan = shape_lifespan\r\n        self.finding_pipeline = finding_pipeline\r\n        self.shapes: Dict[int, ContinuesShape] = {}\r\n        self.track_new = track_new\r\n        self.__args = args\r\n        self.__kwargs = kwargs\r\n        for i, shape in enumerate(shapes):\r\n            self.shapes[i] = self.__create_continues_shape(shape, frame)\r\n        self.__idx = len(shapes)\r\n\r\n    def __create_continues_shape(self, shape, frame) -> ContinuesShape:\r\n        return self.shape_type(shape, frame, Tracker(self.tracker_type), *self.__args, **self.__kwargs)\r\n\r\n    def find_shapes(self, frame: Frame) -> Dict[int, Shape]:\r\n        """\r\n        finds all shapes in the frame, them performs a continues shape operations on them and return the result as a dict where the keys are unique ids and the values are the shapes\r\n        if a shape was lost it removes it from the tracked shapes list\r\n        if a new shape was found and the track_new field is set to True it adds it to the tracked shapes list\r\n\r\n        :param frame: the frame to search in\r\n        :return: a dict mapping from unique ids to shapes, based on continuity\r\n        """\r\n        shapes = self.finding_pipeline(frame)\r\n        result = {}\r\n        to_delete = []\r\n        for i in self.shapes:\r\n            cont_shape = self.shapes[i]\r\n            if cont_shape.is_lost(self.shape_lifespan):\r\n                to_delete.append(i)\r\n                continue\r\n            found = False\r\n            for j, shape in enumerate(shapes):\r\n                if cont_shape.update(shape, frame):\r\n                    found = True\r\n                    del shapes[j]\r\n                    break\r\n            if not found:\r\n                cont_shape.update_forced(frame)\r\n            result[i] = cont_shape.get()\r\n        for i in to_delete:\r\n            del self.shapes[i]\r\n        if self.track_new:\r\n            for shape in shapes:\r\n                self.shapes[self.__idx] = self.__create_continues_shape(shape, frame)\r\n                result[self.__idx] = self.shapes[self.__idx].get()\r\n                self.__idx += 1\r\n        return result\r\n\r\n    def get_shapes(self) -> Dict[int, Shape]:\r\n        """\r\n        returns the current location of the shapes based on continuity\r\n        NOTE! this will be applied to the last frame given to the find_shapes method, only use this method if you need to get the shapes twice in an iteration\r\n\r\n        :return: a dict mapping from unique ids to shapes\r\n        """\r\n        result = {}\r\n        for i in self.shapes:\r\n            result[i] = self.shapes[i].get()\r\n        return result\r\n\r\n    def get_shapes_as_list(self) -> List[Shape]:\r\n        """\r\n        gets all the shapes as a list instead of a dictionary\r\n        :return: a list of all the tracked shapes (sorted by unique id\'s)\r\n        """\r\n        return list(self.get_shapes().values())\r\n')
	__stickytape_write_module('gbvision/utils/finders/__init__.py',
							  b'from .circle_finder import CircleFinder\r\nfrom .contour_finder import ContourFinder\r\nfrom .convex_polygon_finder import ConvexPolygonFinder\r\nfrom .object_finder import ObjectFinder\r\nfrom .polygon_finder import PolygonFinder\r\nfrom .rect_finder import RectFinder\r\nfrom .rotated_rect_finder import RotatedRectFinder\r\n\r\n')
	__stickytape_write_module('gbvision/utils/finders/circle_finder.py',
							  b'from typing import List\r\n\r\nfrom gbvision.constants.types import Circle, Frame, FilterFunction\r\n\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\nfrom gbvision.models.contours import find_contours, FilterContours, contours_to_circles\r\nfrom .object_finder import ObjectFinder\r\nfrom gbvision.utils.shapes.base_circle import BaseCircle\r\n\r\n\r\nclass CircleFinder(ObjectFinder):\r\n    """\r\n    finds specific circular shaped object, and performs distance transformation\r\n\r\n    :param threshold_func: a pipeline (or any sort of function) that returns a binary threshold of the object\r\n     the finder is searching, the object needs to be white and the rest if the image black (doesn\'t\r\n     have to be perfect)\r\n    :param contour_min_area: the minimal area of a contour, used for FilterContours, default is 0 (no area limit)\r\n    :param contours_process: a pipeline to run on the list of contours (optional)\r\n    :param circles_process: a pipeline to run on the list of circles (optional)\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseCircle\r\n\r\n    def __init__(self, threshold_func: FilterFunction, game_object, area_scalar=1.0, contour_min_area=0,\r\n                 contours_process=EMPTY_PIPELINE, circles_process=EMPTY_PIPELINE):\r\n        ObjectFinder.__init__(self, game_object, area_scalar=area_scalar)\r\n        self._full_pipeline = (EMPTY_PIPELINE +\r\n                               threshold_func +\r\n                               find_contours +\r\n                               FilterContours(min_area=contour_min_area) +\r\n                               contours_process +\r\n                               contours_to_circles +\r\n                               circles_process)\r\n\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[Circle]:\r\n        return self._full_pipeline(frame)\r\n\r\n')
	__stickytape_write_module('gbvision/models/system.py',
							  b'from gbvision.utils.pipeline import PipeLine\r\n\r\nEMPTY_PIPELINE = PipeLine()\r\n')
	__stickytape_write_module('gbvision/utils/finders/object_finder.py',
							  b'import abc\r\nfrom typing import List, Iterable\r\n\r\nfrom gbvision.utils.cameras.camera import Camera\r\n\r\nfrom gbvision.constants.types import Frame, Location, Number, Point, Shape\r\nfrom gbvision.utils.game_object import GameObject\r\nfrom gbvision.utils.shapes.base_shape import BaseShapeType\r\n\r\n\r\nclass ObjectFinder(abc.ABC):\r\n    """\r\n    this is an abstract class that represents an object finder\r\n    an object finder is a type that outputs an object\'s 3d real location based on an of it image it\'s\r\n    GameObject real-life parameters\r\n\r\n    :param game_object: the game object descriptor for the real-life parameters of the finder\'s target\r\n    :param area_scalar: a scalar to multiply the root of the area of the shape in the image by, default is 1\r\n    """\r\n\r\n    def __init__(self, game_object: GameObject, area_scalar=1.0):\r\n        self.game_object = game_object\r\n        self.area_scalar = area_scalar\r\n\r\n    def __call__(self, frame: Frame, camera: Camera) -> List[Location]:\r\n        """\r\n        finds all instances of the object in the frame\r\n\r\n        :param frame: the frame in which to find\r\n        :param camera: the camera used to read the frame\r\n        :return: all object of this type in the physical space\r\n        """\r\n        return self.locations_from_shapes(self.find_shapes(frame), camera)\r\n\r\n    @staticmethod\r\n    @abc.abstractmethod\r\n    def _base_shape() -> BaseShapeType:\r\n        """\r\n        returns the base shape matching this finder\r\n\r\n        :return: the base shape (a class that inherits from BaseShape)\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[Shape]:\r\n        """\r\n        finds all the objects and returns them in frame after full pipeline (not sorted)\r\n\r\n        :param: The current frame the finder searches in\r\n        :return: A list of objects: see gbvision/constants/types\r\n        """\r\n\r\n    def find_shapes(self, frame: Frame) -> List[Shape]:\r\n        """\r\n        finds all the objects and returns them in frame after full pipeline (sorted)\r\n\r\n        :param: The current frame the finder searches in\r\n        :return: A list of objects: see gbvision/constants/types\r\n        """\r\n        return self._base_shape().sort_shapes(self.find_shapes_unsorted(frame))\r\n\r\n    @classmethod\r\n    def _shape_root_area(cls, shape: Shape) -> Number:\r\n        return cls._base_shape().shape_root_area(shape)\r\n\r\n    @classmethod\r\n    def _shape_center(cls, shape: Shape) -> Point:\r\n        return cls._base_shape().shape_center(shape)\r\n\r\n    def filter_inner_shapes(self, shapes: List[Shape]) -> List[Shape]:\r\n        """\r\n        filters out all inner shapes in the given sorted list of shapes\r\n\r\n        :param shapes: a sorted list of shapes\r\n        :return: the list of shapes, without any shape intersecting with a larger shape\r\n        """\r\n        return self._base_shape().filter_inner_shapes(shapes)\r\n\r\n    def locations_from_shapes(self, shapes: Iterable[Shape], camera: Camera) -> List[Location]:\r\n        """\r\n        finds the locations of the shapes based on the shape descriptor and camera constants\r\n\r\n        :param shapes: a list of the shapes\r\n        :param camera: the camera used to capture the frame that the shapes were found in\r\n        :return: a list of the locations of all the shapes\r\n        """\r\n        return list(\r\n            map(lambda shape: self.game_object.location_by_params(camera,\r\n                                                                  self._shape_root_area(shape) * self.area_scalar,\r\n                                                                  self._shape_center(shape)), shapes))\r\n')
	__stickytape_write_module('gbvision/utils/finders/contour_finder.py',
							  b'from typing import List\r\n\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\nfrom gbvision.constants.types import Frame, Polygon, FilterFunction\r\nfrom gbvision.models.contours import FilterContours, find_contours, sort_contours\r\nfrom .object_finder import ObjectFinder\r\nfrom ..shapes.base_contour import BaseContour\r\nfrom ..shapes.base_shape import BaseShapeType\r\n\r\n\r\nclass ContourFinder(ObjectFinder):\r\n    """\r\n    finds any generic polygon, not recommended when another finder can be used\r\n\r\n    :param area_scalar: optional, a scalar to multiply the area by, for fine tuning of the function\'s output\r\n    :param contour_min_area: the minimal area of a contour, used for FilterContours, default is 0 (no area limit)\r\n    :param threshold_func: a pipeline (or any sort of function) that returns a binary threshold of the object\r\n     the finder is searching, the object needs to be white and the rest if the image black (doesn\'t\r\n     have to be perfect)\r\n    :param contours_process: a pipeline to run on the list of contours (optional)\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape() -> BaseShapeType:\r\n        return BaseContour\r\n\r\n    def __init__(self, threshold_func: FilterFunction, game_object, area_scalar=1.0, contour_min_area=0.0,\r\n                 contours_process=EMPTY_PIPELINE):\r\n        ObjectFinder.__init__(self, game_object, area_scalar=area_scalar)\r\n        self._full_pipeline = (EMPTY_PIPELINE +\r\n                               threshold_func +\r\n                               find_contours +\r\n                               FilterContours(min_area=contour_min_area) +\r\n                               contours_process)\r\n\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[Polygon]:\r\n        return self._full_pipeline(frame)\r\n')
	__stickytape_write_module('gbvision/utils/finders/convex_polygon_finder.py',
							  b'from typing import List\r\n\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\nfrom gbvision.constants.types import Frame, Polygon, FilterFunction\r\nfrom gbvision.models.contours import FilterContours, find_contours, sort_polygons, contours_to_polygons, \\\r\n    convex_hull_multiple\r\nfrom .object_finder import ObjectFinder\r\nfrom gbvision.utils.shapes.base_convex_polygon import BaseConvexPolygon\r\n\r\n\r\nclass ConvexPolygonFinder(ObjectFinder):\r\n    """\r\n    finds any generic polygon, not recommended when another finder can be used\r\n\r\n    :param area_scalar: optional, a scalar to multiply the area by, for fine tuning of the function\'s output\r\n    :param contour_min_area: the minimal area of a contour, used for FilterContours, default is 0 (no area limit)\r\n    :param threshold_func: a pipeline (or any sort of function) that returns a binary threshold of the object\r\n     the finder is searching, the object needs to be white and the rest if the image black (doesn\'t\r\n     have to be perfect)\r\n    :param contours_process: a pipeline to run on the list of contours (optional)\r\n    :param convex_polygons_process: a pipeline to run on the list of convex polygons (optional)\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseConvexPolygon\r\n\r\n    def __init__(self, threshold_func: FilterFunction, game_object, area_scalar=1.0, contour_min_area=0.0,\r\n                 contours_process=EMPTY_PIPELINE, convex_polygons_process=EMPTY_PIPELINE):\r\n        ObjectFinder.__init__(self, game_object, area_scalar=area_scalar)\r\n        self._full_pipeline = (EMPTY_PIPELINE +\r\n                               threshold_func +\r\n                               find_contours +\r\n                               FilterContours(min_area=contour_min_area) +\r\n                               contours_process +\r\n                               convex_hull_multiple +\r\n                               contours_to_polygons +\r\n                               convex_polygons_process)\r\n\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[Polygon]:\r\n        return self._full_pipeline(frame)\r\n')
	__stickytape_write_module('gbvision/utils/finders/polygon_finder.py',
							  b'from typing import List\r\n\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\nfrom gbvision.constants.types import Frame, Polygon, FilterFunction\r\nfrom gbvision.models.contours import FilterContours, find_contours, contours_to_polygons\r\nfrom .object_finder import ObjectFinder\r\nfrom gbvision.utils.shapes.base_polygon import BasePolygon\r\n\r\n\r\nclass PolygonFinder(ObjectFinder):\r\n    """\r\n    finds any generic polygon, not recommended when another finder can be used\r\n\r\n    :param area_scalar: optional, a scalar to multiply the area by, for fine tuning of the function\'s output\r\n    :param contour_min_area: the minimal area of a contour, used for FilterContours, default is 0 (no area limit)\r\n    :param threshold_func: a pipeline (or any sort of function) that returns a binary threshold of the object\r\n     the finder is searching, the object needs to be white and the rest if the image black (doesn\'t\r\n     have to be perfect)\r\n    :param contours_process: a pipeline to run on the list of contours (optional)\r\n    :param polygons_process: a pipeline to run on the list of polygons (optional)\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BasePolygon\r\n\r\n    def __init__(self, threshold_func: FilterFunction, game_object, area_scalar=1.0, contour_min_area=0.0,\r\n                 contours_process=EMPTY_PIPELINE, polygons_process=EMPTY_PIPELINE):\r\n        ObjectFinder.__init__(self, game_object, area_scalar=area_scalar)\r\n        self._full_pipeline = (EMPTY_PIPELINE +\r\n                               threshold_func +\r\n                               find_contours +\r\n                               FilterContours(min_area=contour_min_area) +\r\n                               contours_process +\r\n                               contours_to_polygons +\r\n                               polygons_process)\r\n\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[Polygon]:\r\n        return self._full_pipeline(frame)\r\n')
	__stickytape_write_module('gbvision/utils/finders/rect_finder.py',
							  b'from typing import List\r\n\r\nfrom gbvision.constants.types import Frame, Rect, FilterFunction\r\n\r\nfrom .object_finder import ObjectFinder\r\nfrom gbvision.models.contours import find_contours, contours_to_rects, FilterContours\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\n\r\nfrom gbvision.utils.shapes.base_rect import BaseRect\r\n\r\n\r\nclass RectFinder(ObjectFinder):\r\n    """\r\n    finds a rectangular shaped object\r\n\r\n    :param area_scalar: optional, a scalar to multiply the area by, for fine tuning of the function\'s output\r\n    :param contour_min_area: the minimal area of a contour, used for FilterContours, default is 0 (no area limit)\r\n    :param threshold_func: a pipeline (or any sort of function) that returns a binary threshold of the object\r\n     the finder is searching, the object needs to be white and the rest if the image black (doesn\'t\r\n     have to be perfect)\r\n    :param contours_process: a pipeline to run on the list of contours (optional)\r\n    :param rects_process: a pipeline to run on the list of rects (optional)\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseRect\r\n\r\n    def __init__(self, threshold_func: FilterFunction, game_object, area_scalar=1.0, contour_min_area=0.0,\r\n                 contours_process=EMPTY_PIPELINE, rects_process=EMPTY_PIPELINE):\r\n        ObjectFinder.__init__(self, game_object, area_scalar=area_scalar)\r\n        self._full_pipeline = (EMPTY_PIPELINE +\r\n                               threshold_func +\r\n                               find_contours +\r\n                               FilterContours(min_area=contour_min_area) +\r\n                               contours_process +\r\n                               contours_to_rects +\r\n                               rects_process)\r\n\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[Rect]:\r\n        return self._full_pipeline(frame)\r\n')
	__stickytape_write_module('gbvision/utils/finders/rotated_rect_finder.py',
							  b'from typing import List\r\n\r\nfrom gbvision.constants.types import Frame, RotatedRect, FilterFunction\r\n\r\nfrom gbvision.models.system import EMPTY_PIPELINE\r\nfrom gbvision.models.contours import find_contours, FilterContours, contours_to_rotated_rects\r\nfrom .object_finder import ObjectFinder\r\nfrom gbvision.utils.shapes.base_rotated_rect import BaseRotatedRect\r\n\r\n\r\nclass RotatedRectFinder(ObjectFinder):\r\n    """\r\n    finds a rectangular object, but rotated. recommended to use when you know the shape isn\'t parallel to the camera\r\n\r\n    :param threshold_func: a pipeline (or any sort of function) that returns a binary threshold of the object\r\n     the finder is searching, the object needs to be white and the rest if the image black (doesn\'t\r\n     have to be perfect)\r\n    :param area_scalar: optional, a scalar to multiply the area by, for fine tuning of the function\'s output\r\n    :param contour_min_area: the minimal area of a contour, used for FilterContours, default is 0 (no area limit)\r\n    :param contours_process: a pipeline to run on the list of contours (optional)\r\n    :param rotated_rects_process: a pipeline to run on the list of rotated rects (optional)\r\n    """\r\n\r\n    @staticmethod\r\n    def _base_shape():\r\n        return BaseRotatedRect\r\n\r\n    def __init__(self, threshold_func: FilterFunction, game_object, area_scalar=1.0, contour_min_area=0.0,\r\n                 contours_process=EMPTY_PIPELINE, rotated_rects_process=EMPTY_PIPELINE):\r\n        ObjectFinder.__init__(self, game_object, area_scalar=area_scalar)\r\n        self._full_pipeline = (EMPTY_PIPELINE +\r\n                               threshold_func +\r\n                               find_contours +\r\n                               FilterContours(min_area=contour_min_area) +\r\n                               contours_process +\r\n                               contours_to_rotated_rects +\r\n                               rotated_rects_process)\r\n\r\n    def find_shapes_unsorted(self, frame: Frame) -> List[RotatedRect]:\r\n        return self._full_pipeline(frame)\r\n')
	__stickytape_write_module('gbvision/utils/thresholds/__init__.py',
							  b'from .threshold import Threshold, ThresholdGroup\r\nfrom .color_threshold import ColorThreshold\r\n')
	__stickytape_write_module('gbvision/utils/thresholds/threshold.py',
							  b'import abc\r\nfrom typing import List, Callable\r\n\r\nimport cv2\r\nimport numpy as np\r\nfrom gbvision.constants.math import EPSILON\r\n\r\nfrom gbvision.constants.types import FilterFunction, Frame\r\n\r\n\r\nclass Threshold(abc.ABC):\r\n    """\r\n    a class that represents a function that maps from an image to a binary image\r\n    where 255 states that the pixel at the original image was in a range represented by the threshold object\r\n    and 0 states the pixel was out of the range\r\n    for example:\r\n    ColorThreshold([[200, 255], [0, 50], [0, 50]], \'RGB\')\r\n    the above threshold represents a relatively red pixel. when an image is filtered by it, every pixel that is\r\n    relatively red will be given the value 255, and every pixel that isn\'t will be given the value of 0\r\n    """\r\n\r\n    @abc.abstractmethod\r\n    def _threshold(self, frame: Frame) -> Frame:\r\n        """\r\n        unsafely activates the threshold filter on the given image\r\n        :param frame: the image to activate the threshold on\r\n        :return: a binary image, the frame after the threshold filter\r\n        """\r\n\r\n    def __call__(self, frame: Frame) -> Frame:\r\n        frame = self._threshold(frame)\r\n        if frame.dtype == np.uint8:\r\n            return frame\r\n        frame *= 255.0 / (np.max(frame) + EPSILON)\r\n        return frame.astype(np.uint8)\r\n\r\n    def __or__(self, other: \'Threshold\') -> \'Threshold\':\r\n        return ThresholdGroup(cv2.bitwise_or, self, other)\r\n\r\n    def __and__(self, other: \'Threshold\') -> \'Threshold\':\r\n        return ThresholdGroup(cv2.bitwise_and, self, other)\r\n\r\n\r\nclass ThresholdGroup(Threshold):\r\n    """\r\n    a class that constructs a threshold filter out of several threshold filters and a binary mask function\r\n    for example, use of the function on two thresholds with the binary function "bitwise_or" will result\r\n    in a filter that outputs 255 for a pixel if it is in either one of the threshold\'s range\r\n    using the "bitwise_and" function will output 255 for a pixel only if it is in both the threshold\'s range\r\n\r\n    :param thresholds: all the thresholds to join in the threshold group\r\n    :param binary_mask: a binary function that maps from a pair of binary images to a single binary image\r\n        default value is cv2.bitwise_or\r\n    """\r\n\r\n    def __init__(self, binary_mask: Callable[[Frame, Frame], Frame], *thresholds):\r\n        self.binary_mask = binary_mask\r\n        self.thresholds: List[Threshold] = list(thresholds)\r\n\r\n    def _threshold(self, frame: Frame) -> Frame:\r\n        """\r\n        apply the threshold filter to the frame\r\n        :param frame: the frame to apply the filter to\r\n        :return: the binary image, the frame after the threshold group filter\r\n        """\r\n        if len(self.thresholds) == 0:\r\n            return frame\r\n        frame_tag = self.thresholds[0](frame)\r\n        for i in range(1, len(self.thresholds)):\r\n            frame_tag = self.binary_mask(frame_tag, self.thresholds[i](frame))\r\n        return frame_tag\r\n\r\n    def __iter__(self):\r\n        """\r\n        :return: an iterator that iterates through all this group\'s filters\r\n        """\r\n        return iter(self.thresholds)\r\n\r\n    def __len__(self):\r\n        """\r\n        :return: the amount of filters in this threshold group\r\n        """\r\n        return len(self.thresholds)\r\n\r\n    def __getitem__(self, item: int) -> FilterFunction:\r\n        return self.thresholds[item]\r\n\r\n    def __setitem__(self, key: int, value: FilterFunction):\r\n        self.thresholds[key] = value\r\n')
	__stickytape_write_module('gbvision/utils/thresholds/color_threshold.py',
							  b'from typing import List, Tuple, Union\r\n\r\nimport cv2\r\n\r\nfrom gbvision.utils.thresholds.threshold import Threshold\r\nfrom gbvision.constants.types import Number\r\n\r\n\r\ndef bgr_threshold(frame, params):\r\n    red, green, blue = params\r\n    return cv2.inRange(frame, (red[0], green[0], blue[0]), (red[1], green[1], blue[1]))\r\n\r\n\r\nclass __ColorThresholdFunction:\r\n    def __init__(self, color_type):\r\n        self.color_type = color_type\r\n\r\n    def __call__(self, frame, params):\r\n        frame = cv2.cvtColor(frame, self.color_type)\r\n        return bgr_threshold(frame, params)\r\n\r\n\r\nhls_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2HLS)\r\nhsv_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2HSV)\r\nrgb_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2RGB)\r\nluv_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2LUV)\r\nlab_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2LAB)\r\nyuv_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2YUV)\r\nxyz_threshold = __ColorThresholdFunction(cv2.COLOR_BGR2XYZ)\r\n\r\n\r\ndef gray_threshold(frame, params):\r\n    if len(frame.shape) > 2:\r\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n    return cv2.threshold(frame, params[0][0], params[0][1], cv2.THRESH_BINARY)[1]\r\n\r\n\r\n_THRESHOLD_NAME_TABLE = {\r\n    \'BGR\': bgr_threshold,\r\n    \'RGB\': rgb_threshold,\r\n    \'HLS\': hls_threshold,\r\n    \'HSV\': hsv_threshold,\r\n    \'LUV\': luv_threshold,\r\n    \'LAB\': lab_threshold,\r\n    \'YUV\': yuv_threshold,\r\n    \'XYZ\': xyz_threshold,\r\n    \'GRAY\': gray_threshold\r\n}\r\n\r\n\r\nclass ColorThreshold(Threshold):\r\n    """\r\n    a class that represents a function that maps from an image to a binary image\r\n    where 255 states that the pixel at the original image was in a range represented by the threshold object\r\n    and 0 states the pixel was out of the range\r\n    for example:\r\n    Threshold([[200, 255], [0, 50], [0, 50]], \'RGB\')\r\n    the above threshold represents a relatively red pixel. when an image is filtered by it, every pixel that is\r\n    relatively red will be given the value 255, and every pixel that isn\'t will be given the value of 0\r\n\r\n\r\n    :param pixel_range: the threshold parameters, as a list of integers\r\n        in the shape of 3x2 for a color image and 1x2 for a gray image\r\n    :param thresh_type: a string, the type of color encoding to transform the image before applying the range test \\\r\n        binary filter \\\r\n        can be selected from the given list: \\\r\n        \'BGR\': default opencv color encoding (no change) \\\r\n        \'RGB\': default opencv color encoding in reverse \\\r\n        \'HLS\': hue, luminous, saturation \\\r\n        \'HSV\': hue, saturation, value \\\r\n        \'LUV\': https://en.wikipedia.org/wiki/CIELUV \\\r\n        \'LAB\': https://en.wikipedia.org/wiki/CIELAB_color_space \\\r\n        \'YUV\': https://en.wikipedia.org/wiki/YUV \\\r\n        \'XYZ\': https://en.wikipedia.org/wiki/CIE_1931_color_space \\\r\n        \'GRAY\': grayscale images (single channel), image presented doesn\'t have to be gray, the threshold will convert it\r\n    """\r\n\r\n    THRESH_TYPE_BGR = \'BGR\'\r\n    THRESH_TYPE_RGB = \'RGB\'\r\n    THRESH_TYPE_HLS = \'HLS\'\r\n    THRESH_TYPE_HSV = \'HSV\'\r\n    THRESH_TYPE_LUV = \'LUV\'\r\n    THRESH_TYPE_LAB = \'LAB\'\r\n    THRESH_TYPE_YUV = \'YUV\'\r\n    THRESH_TYPE_XYZ = \'XYZ\'\r\n    THRESH_TYPE_GRAY = \'GRAY\'\r\n\r\n    def __init__(self, pixel_range: List[Union[Tuple[Number, Number], List[Number]]], thresh_type=\'HSV\'):\r\n        assert thresh_type.upper() in _THRESHOLD_NAME_TABLE\r\n        self.params = pixel_range\r\n        self.type = thresh_type.upper()\r\n\r\n    def __len__(self):\r\n        """\r\n        the amount of parameters is equal to the amount of channels\r\n\r\n        :return: 1 if the threshold is for grayscale images, 3 if it is for color images\r\n        """\r\n        return len(self.params)\r\n\r\n    def __getitem__(self, item: int):\r\n        """\r\n        returns the item\'th channel\'s range\r\n\r\n        :param item: the index\r\n        :return: the range of the pixel in the item\'th channel\r\n        """\r\n        return self.params[item]\r\n\r\n    def __setitem__(self, key: int, value: list or tuple):\r\n        """\r\n        sets the key\'th channel\'s range to value\r\n\r\n        :param key: the channel\r\n        :param value: an array of 2 integers, the lower and upper bounds of the pixel\r\n        """\r\n        self.params[key] = value\r\n\r\n    def __iter__(self):\r\n        """\r\n        :return: an iterator that iterates through the channel ranges\r\n        """\r\n        return iter(self.params)\r\n\r\n    def _threshold(self, frame):\r\n        """\r\n        activates the threshold filter on the given image\r\n        :param frame: the image to activate the threshold on\r\n        :return: a binary image, the frame after the threshold filter\r\n        """\r\n        return _THRESHOLD_NAME_TABLE[self.type](frame, self.params)\r\n\r\n    def __repr__(self):\r\n        return f\'<{self}>\'\r\n\r\n    def __str__(self):\r\n        return f"ColorThreshold({self.params}, \'{self.type}\')"\r\n')
	__stickytape_write_module('gbvision/utils/recorders/__init__.py',
							  b'from .recorder import Recorder\r\nfrom .opencv_recorder import OpenCVRecorder\r\n')
	__stickytape_write_module('gbvision/utils/recorders/recorder.py',
							  b'import abc\r\n\r\nfrom gbvision.constants.types import Frame\r\n\r\n\r\nclass Recorder(abc.ABC):\r\n    """\r\n    An abstract recorder class\r\n    records a given feed of frames into a file\r\n\r\n    :param file_name: the file name\r\n    """\r\n    def __init__(self, file_name):\r\n        self.file_name = file_name\r\n\r\n    @abc.abstractmethod\r\n    def record(self, frame: Frame):\r\n        """\r\n        records the frame\r\n\r\n        :param frame: the frame to record\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def close(self):\r\n        """\r\n        ends the writing to the file\r\n\r\n        """\r\n\r\n    @abc.abstractmethod\r\n    def is_opened(self) -> bool:\r\n        """\r\n        checks if this video file is opened\r\n\r\n        :return: True if this is opened, False otherwise\r\n        """')
	__stickytape_write_module('gbvision/utils/recorders/opencv_recorder.py',
							  b'from os.path import splitext\r\nfrom typing import Optional\r\n\r\nimport cv2\r\nfrom gbvision.constants.video import VIDEO_FILE_TYPE\r\n\r\nfrom .recorder import Recorder\r\n\r\n\r\nclass OpenCVRecorder(Recorder):\r\n    """\r\n    a basic implementation of the recorder class using OpenCV\r\n\r\n    :param file_name: the path to the output file\r\n    :param fps: the fps of the video\r\n    :param width: optional, the width of the video (will be set automatically if not given)\r\n    :param height: optional, the height of the video (will be set automatically if not given)\r\n    """\r\n    def __init__(self, file_name, fps, width=None, height=None):\r\n        Recorder.__init__(self, file_name)\r\n\r\n        _, file_ext = splitext(file_name)\r\n\r\n        self.fourcc = cv2.VideoWriter_fourcc(*VIDEO_FILE_TYPE[file_ext.upper()])\r\n\r\n        self.fps = fps\r\n\r\n        self.video_writer: Optional[cv2.VideoWriter] = None\r\n        self.width = width\r\n        self.height = height\r\n\r\n    def record(self, frame):\r\n        if frame is None or len(frame.shape) == 0:\r\n            return\r\n        if self.video_writer is None:\r\n            self.width = self.width if self.width is not None else frame.shape[1]\r\n            self.height = self.height if self.height is not None else frame.shape[0]\r\n            self.video_writer = cv2.VideoWriter()\r\n            self.video_writer.open(self.file_name, self.fourcc, self.fps, (self.width, self.height))\r\n        self.video_writer.write(frame)\r\n\r\n    def close(self):\r\n        self.video_writer.release()\r\n\r\n    def is_opened(self) -> bool:\r\n        if self.video_writer is None:\r\n            return True\r\n        return self.video_writer.isOpened()\r\n')
	__stickytape_write_module('gbvision/utils/denoising/__init__.py',
							  b'from .erode import Erode\r\nfrom .dilate import Dilate\r\nfrom .erode_and_dilate import ErodeAndDilate\r\nfrom .median_blur import MedianBlur\r\nfrom .distance_transform_threshold import DistanceTransformThreshold\r\n')
	__stickytape_write_module('gbvision/utils/denoising/erode.py',
							  b'from typing import Union, Tuple\r\nimport cv2\r\nimport numpy as np\r\n\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\nclass Erode(PipeLine):\r\n    """\r\n    creates a pipeline that erodes the image by a kernel of ones\r\n    used mainly for Erode & Dilate denoise filters\r\n\r\n    :param ksize: the kernel size, either an integer (meaning an nxn kernel) or a tuple (nxm kernel)\r\n    :param iterations: optional, the amount of Erode iterations to perform, default is 1.\r\n        Note! a large number of iterations will slow down the program\r\n    :return: a pipeline that erodes the given frame\r\n    """\r\n\r\n    def __init__(self, ksize: Union[int, Tuple[int, int]], iterations=1):\r\n        if type(ksize) is int:\r\n            ksize = (ksize, ksize)\r\n        PipeLine.__init__(self, lambda frame: cv2.erode(frame, np.ones(ksize), iterations=iterations))\r\n')
	__stickytape_write_module('gbvision/utils/denoising/dilate.py',
							  b'from typing import Union, Tuple\r\nimport cv2\r\nimport numpy as np\r\n\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\nclass Dilate(PipeLine):\r\n    """\r\n        creates a pipeline that dilates the image by a kernel of ones\r\n        used mainly for Erode & Dilate denoise filters\r\n\r\n        :param ksize: the kernel size, either an integer (meaning an nxn kernel) or a tuple (nxm kernel)\r\n        :param iterations: optional, the amount of Dilate iterations to perform, default is 1.\r\n            Note! a large number of iterations will slow down the program\r\n        :return: a pipeline that dilates the given frame\r\n        """\r\n\r\n    def __init__(self, ksize: Union[int, Tuple[int, int]], iterations=1):\r\n        if type(ksize) is int:\r\n            ksize = (ksize, ksize)\r\n        PipeLine.__init__(self, lambda frame: cv2.dilate(frame, np.ones(ksize), iterations=iterations))\r\n')
	__stickytape_write_module('gbvision/utils/denoising/erode_and_dilate.py',
							  b'from typing import Union, Tuple\r\n\r\nfrom .erode import Erode\r\nfrom .dilate import Dilate\r\n\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\nclass ErodeAndDilate(PipeLine):\r\n    """\r\n    a pipeline class that erodes and dilates the given frame by the same kernel\r\n\r\n    :param ksize: the kernel size, either an integer (meaning an nxn kernel) or a tuple (nxm kernel)\r\n    :param iterations: optional, the amount of Dilate iterations to perform, default is 1.\r\n            Note! a large number of iterations will slow down the program\r\n    """\r\n\r\n    def __init__(self, ksize: Union[int, Tuple[int, int]], iterations=1):\r\n        PipeLine.__init__(self)\r\n        self.functions += (Erode(ksize, iterations) + Dilate(ksize, iterations)).functions\r\n')
	__stickytape_write_module('gbvision/utils/denoising/median_blur.py',
							  b'import cv2\r\n\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\nclass MedianBlur(PipeLine):\r\n    """\r\n    creates a pipeline that blurs the given frame using the median blur method\r\n    works very good for denoising purposes\r\n\r\n    :param ksize: the size of the kernel used by the filter, must be an odd number\r\n    :return: a pipeline that filters the image using the median blur method\r\n    """\r\n\r\n    def __init__(self, ksize: int):\r\n        PipeLine.__init__(self, lambda frame: cv2.medianBlur(frame, ksize))\r\n')
	__stickytape_write_module('gbvision/utils/denoising/distance_transform_threshold.py',
							  b'from gbvision.utils.thresholds.color_threshold import ColorThreshold\r\nfrom gbvision.utils.pipeline import PipeLine\r\n\r\n\r\nclass DistanceTransformThreshold(PipeLine):\r\n    """\r\n    a pipeline factory that performs normalized distance transform and then a minimum threshold on the frame which\r\n    removes from the original frame all white pixels that are at most min_distance_ratio normalized distance from the\r\n    nearest black frame\r\n\r\n    :param min_distance_ratio: the minimum ratio between the maximum distance of a pixel from a white pixel in the\r\n        frame and a certain pixel for it to be included in the threshold, between 0 and 1\r\n    """\r\n    def __init__(self, min_distance_ratio: float):\r\n        PipeLine.__init__(self)\r\n        from gbvision.models.basic_ops import normalized_distance_transform\r\n        self.functions += (normalized_distance_transform + ColorThreshold([[min_distance_ratio, 1.0]],\r\n                                                                          ColorThreshold.THRESH_TYPE_GRAY)).functions\r\n')
	__stickytape_write_module('gbvision/tools/__init__.py',
							  b'from .finding_tools import viewing_angle_of_object, plane_distance_from_object, plane_angle_by_location, \\\r\n    distance_from_object\r\nfrom .image_tools import crop, median_threshold\r\nfrom .list_tools import split_list\r\n')
	__stickytape_write_module('gbvision/tools/finding_tools.py',
							  b'import numpy as np\r\n\r\nfrom gbvision.constants.types import Location\r\n\r\n\r\ndef distance_from_object(loc: Location) -> float:\r\n    """\r\n    the absolute distance from the camera to this object\r\n\r\n    :param loc: the object\'s location (2d or 3d)\r\n    :returns: the absolute distance (float)\r\n    """\r\n    if len(loc) <= 3:\r\n        return np.linalg.norm(loc)\r\n    return np.linalg.norm(loc[:3])\r\n\r\n\r\ndef plane_angle_by_location(loc: Location) -> float:\r\n    """\r\n    calculates the angle from the camera to the object\'s projection on the x-z plane (y=0 plane)\r\n\r\n    :param loc: the 3d location\r\n    :return: the angle (in radians)\r\n    """\r\n    return np.arctan(loc[0] / loc[2])\r\n\r\n\r\ndef plane_distance_from_object(loc: Location) -> float:\r\n    """\r\n    calculates the distance from the object\'s projection on the x-z plane (y=0 plane)\r\n    the distance on the y axis is ignored in this calculation\r\n    \r\n    :param loc: the 3d location\r\n    :return: the distance without regarding the y axis\r\n    """\r\n    return np.sqrt(loc[0] ** 2 + loc[2] ** 2)\r\n\r\n\r\ndef viewing_angle_of_object(part1: Location, part2: Location, x_distance: float) -> float:\r\n    """\r\n    finds the viewing angle of an object based on a split of the object to two parts (part1 and part2), and the x \\\r\n    distance between those two parts in real life (in meters)\r\n\r\n    :param part1: the first part of the object (the left one)\r\n    :param part2: the second part of the object (the right one)\r\n    :param x_distance: the distance between the two objects in meters\r\n\r\n    :return: the viewing angle of the object\r\n    """\r\n    return np.pi / 2 - np.arccos(max(-1, min(1, (part1[2] - part2[2]) / x_distance)))\r\n')
	__stickytape_write_module('gbvision/tools/image_tools.py',
							  b'from typing import Union\r\n\r\nimport cv2\r\nimport numpy as np\r\n\r\nfrom gbvision.constants.types import Frame, Number, ROI\r\nfrom gbvision.utils.thresholds import ColorThreshold\r\nfrom gbvision.utils.thresholds.threshold import Threshold\r\n\r\n\r\ndef crop(frame: Frame, x: int, y: int, w: int, h: int) -> Frame:\r\n    """\r\n    crops the image from (x, y) to (x+w, y+h)\r\n\r\n    :param frame: the frame to crop\r\n    :param x: the x coordinate to crop from\r\n    :param y: the y coordinate to crop from\r\n    :param w: the width of the cropped image\r\n    :param h: the height of the cropped image\r\n    :return: the cropped image\r\n    """\r\n    return frame[y:y + h, x:x + w]\r\n\r\n\r\ndef median_threshold(frame: Frame, stdv: Union[Number, np.ndarray],\r\n                     box: Union[None, ROI] = None, color_encoding=ColorThreshold.THRESH_TYPE_BGR) -> Threshold:\r\n    """\r\n    finds a threshold using the median threshold method\r\n    the median threshold method defines the lower bounds of the threshold as the median of a given region of the image\r\n    minus some deviation variable, and the upper bounds as the same median plus the deviation variable\r\n    in a mathematical term, the threshold is defined to be [median(X) - V, median(X) + V] where X is the frame region\r\n    and V is the deviation variable\r\n\r\n    :param frame: the frame\r\n    :param stdv: the deviation variable, can be a scalar (same deviation for every channel) or a numpy array with the\r\n        same size as the number of channels in the threshold, the deviation will be defined for each channel separately\r\n    :param box: optional, a sub region of the frame from which the median is calculated, when set to None the median is\r\n        calculated from the entire frame\r\n    :param color_encoding: the type of color encoding the threshold should use, default is BGR\r\n    :return: a Threshold object\r\n    """\r\n    from gbvision.constants.images import COLOR_TYPE\r\n\r\n    if box is not None:\r\n        frame = crop(frame, *box)\r\n    color_encoding = color_encoding.upper()\r\n    if color_encoding != ColorThreshold.THRESH_TYPE_BGR:\r\n        frame = cv2.cvtColor(frame, COLOR_TYPE[color_encoding])\r\n    med = np.median(frame, axis=(0, 1)).astype(int)\r\n    if type(med) is not np.ndarray:\r\n        med = np.array([med])\r\n    params = list(map(lambda x: list(map(int, x)),\r\n                      np.vectorize(lambda x: min(255, max(0, x)))(np.array([med - stdv, med + stdv])).T))\r\n    return ColorThreshold(params, color_encoding)\r\n')
	__stickytape_write_module('gbvision/tools/list_tools.py',
							  b'from typing import Callable, Iterable, T\r\n\r\n\r\ndef split_list(f: Callable[[T], int], lst: Iterable[T], amount=2):\r\n    """\r\n    splits the list into several list according to the function f\r\n\r\n    :param lst: the list to split\r\n    :param f: a function which maps from an argument to the index of the list it should go to\r\n        for example if we wanted a function to split a list into a list of positive and negative number f could look like\r\n        lambda x: int(x >= 0)\r\n    :param amount: the amount of lists to split the data to (2 by default)\r\n    :return: a tuple of all the lists created,\r\n    """\r\n    temp = tuple([] for _ in range(amount))\r\n    for i in lst:\r\n        temp[f(i)].append(i)\r\n    return temp\r\n')
	import gbvision as gbv


	def runPipeline(image, llrobot):

		return largestContour, image, llpython


	def main():
		print("Hello World")


	if __name__ == '__main__':
		main()
